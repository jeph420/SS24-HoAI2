{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "welsh-brave",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Hands-on AI II</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\">Unit 2 &ndash; The Vanishing Gradient Problem</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-tourism",
   "metadata": {},
   "source": [
    "<b>Authors:</b> B. Schäfl, S. Lehner, J. Brandstetter, A. Schörgenhumer<br>\n",
    "<b>Date:</b> 21-03-2023\n",
    "\n",
    "This file is part of the \"Hands-on AI II\" lecture material. The following copyright statement applies to all code within this file.\n",
    "\n",
    "<b>Copyright statement:</b><br>\n",
    "This material, no matter whether in printed or electronic form, may be used for personal and non-commercial educational use only. Any reproduction of this material, no matter whether as a whole or in parts, no matter whether in printed or in electronic form, requires explicit prior acceptance of the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-innocent",
   "metadata": {},
   "source": [
    "<h2>Table of contents</h2>\n",
    "<ol>\n",
    "    <a href=\"#vanishing-gradient-nutshell\"><li style=\"font-size:large;font-weight:bold\">The Vanishing Gradient Problem in a Nutshell</li></a>\n",
    "    <ol style=\"margin-bottom:15px\">\n",
    "        <a href=\"#disclaimer\"><li style=\"font-size:medium\">Disclaimer</li></a>\n",
    "        <a href=\"#fashion-mnist\"><li style=\"font-size:medium\">Fashion-MNIST</li></a>\n",
    "    </ol>\n",
    "    <a href=\"#training-neural-network\"><li style=\"font-size:large;font-weight:bold\">Training of a Neural Network</li></a>\n",
    "    <ol style=\"margin-bottom:15px\">\n",
    "        <a href=\"#forward-pass\"><li style=\"font-size:medium\">Forward pass</li></a>\n",
    "        <a href=\"#backward-pass\"><li style=\"font-size:medium\">Backward pass</li></a>\n",
    "    </ol>\n",
    "    <a href=\"#logistic-regression\"><li style=\"font-size:large;font-weight:bold\">Vanishing Gradients in Logistic Regression</li></a>\n",
    "    <ol style=\"margin-bottom:15px\">\n",
    "        <a href=\"#adding-hidden-layer-one\"><li style=\"font-size:medium\">Adding a hidden layer</li></a>\n",
    "        <a href=\"#adding-hidden-layer-two\"><li style=\"font-size:medium\">Adding a second hidden layer</li></a>\n",
    "        <a href=\"#adding-hidden-layer-three\"><li style=\"font-size:medium\">Adding a third hidden layer</li></a>\n",
    "        <a href=\"#logistic-regression-gradients\"><li style=\"font-size:medium\">Analyzing gradients</li></a>\n",
    "    </ol>\n",
    "        <a href=\"#vanishing-gradient\"><li style=\"font-size:large;font-weight:bold\">The Vanishing Gradient Problem (Revised)</li></a>\n",
    "    <ol style=\"margin-bottom:15px\">\n",
    "        <a href=\"#vanishing-gradient-culprit\"><li style=\"font-size:medium\">The primary culprit</li></a>\n",
    "        <a href=\"#vanishing-gradient-relu\"><li style=\"font-size:medium\">Rectified linear units to the rescue</li></a>\n",
    "        <a href=\"#training-relu\"><li style=\"font-size:medium\">Training of a ReLU-Network</li></a>\n",
    "    </ol>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-transformation",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">How to use this notebook</h3>\n",
    "\n",
    "This notebook is designed to run from start to finish. There are different tasks (displayed in <span style=\"color:rgb(248,138,36)\">orange boxes</span>) which might require small code modifications. Most/All of the used functions are imported from the file <code>u2_utils.py</code> which can be seen and treated as a black box. However, for further understanding, you can look at the implementations of the helper functions. In order to run this notebook, the packages which are imported at the beginning of <code>u2_utils.py</code> need to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "signal-parish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .output_png {\n",
       "            display: table-cell;\n",
       "            text-align: center;\n",
       "            vertical-align: middle;\n",
       "        }\n",
       "        .jp-RenderedImage {\n",
       "            display: table-cell;\n",
       "            text-align: center;\n",
       "            vertical-align: middle;\n",
       "        }\n",
       "    </style>\n",
       "    <p>Setting up notebook ... finished.</p>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pre-defined utilities specific to this notebook.\n",
    "import u2_utils as u2\n",
    "\n",
    "# Import additional utilities needed in this notebook.\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from typing import Dict, Sequence\n",
    "\n",
    "# Set default plotting style.\n",
    "sns.set()\n",
    "\n",
    "# Setup Jupyter notebook (warning: this may affect all Jupyter notebooks running on the same Jupyter server).\n",
    "u2.setup_jupyter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-china",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Module versions</h3>\n",
    "\n",
    "As mentioned in the introductory slides, specific minimum versions of Python itself as well as of used modules are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "psychological-margin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed Python version: 3.10 (✓)\n",
      "Installed numpy version: 1.26.4 (✓)\n",
      "Installed pandas version: 2.2.1 (✓)\n",
      "Installed PyTorch version: 2.2.2+cu121 (✓)\n",
      "Installed scikit-learn version: 1.4.1.post1 (✓)\n",
      "Installed matplotlib version: 3.8.4 (✓)\n",
      "Installed seaborn version: 0.13.2 (✓)\n"
     ]
    }
   ],
   "source": [
    "u2.check_module_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-affairs",
   "metadata": {},
   "source": [
    "<a name=\"vanishing-gradient-nutshell\"></a><h2>The Vanishing Gradient Problem in a Nutshell</h2>\n",
    "<p>In Machine Learning, and especially in Deep Learning, the <i>Vanishing Gradient Problem</i> is often observed when training neural networks with <i>gradient descent by backpropagation</i>. The weights of a neural network receive an update proportional to the <i>partial derivative</i> of the error function with respect to themselves. In some specific cases, however, the gradient will be vanishingly small, effectively preventing the weights from adapting their value. In the worst case, this may completely stop a neural network from further training.</p>\n",
    "    \n",
    "<p>As prominent examples, traditional activation functions such as the <i>sigmoid</i> function or the <i>hyperbolic tangent</i> function have gradients in the range of $(0; 0.25]$ and $(0; 1]$, respectively. Gradient descent by backpropagation computes the gradients by the chain rule, hence this effectively <i>multiplies many small numbers</i> to compute gradients of the first layers in a network. As a result, the gradient (error signal) decreases exponentially and the first layers adapt very slowly &ndash; if at all.</p>\n",
    "\n",
    "<p>Hochreiter's diploma thesis of 1991 formally identified the reason for this failure in the <i>Vanishing Gradient Problem</i>, which not only affects many-layered feedforward networks, but also recurrent networks.</p>\n",
    "<center><cite>Untersuchungen zu dynamischen neuronalen Netzen. Sepp Hochreiter. Master's thesis, Institut fur Informatik, Technische Universität, München</cite></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-locator",
   "metadata": {},
   "source": [
    "<a name=\"disclaimer\"></a><h3 style=\"color:rgb(0,120,170)\">Disclaimer</h3>\n",
    "<p>The neural networks applied in this unit are not targeted to deliver highest performance but to elaborate on the understanding of the <i>Vanishing Gradient Problem</i>. Moreover, you'll be working with data sets already known to you, as this shifts the focus away from a possible unknown data source towards the gist of this unit: understandind the gradient flow in neural networks.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-spice",
   "metadata": {},
   "source": [
    "<a name=\"fashion-mnist\"></a><h3 style=\"color:rgb(0,120,170)\">Fashion-MNIST</h3>\n",
    "<p>Starting from this section, you will be working with a data set composed of various <i>images</i> of fashion items (e.g., shoes or shirts). You should already be familiar with it, if not, the data set distinguishes <i>ten</i> different classes, one for each type of fashion item. For curious minds, more information regarding this data set can be found at:\n",
    "\n",
    "<center><cite>Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747</cite></center>\n",
    "\n",
    "Summarizing, the popular Fashion-MNIST data set contains grayscale images of  $n=70000$ different fashion items from ten different classes, namely:</p>\n",
    "\n",
    "| Target   | Name        | Examples                                                  |\n",
    "|:--------:|:-----------:|:---------------------------------------------------------:|\n",
    "| 0        | T-shirt/top | ![Image not found!](resources/fashion_mnist_sprite_0.png) |\n",
    "| 1        | Trouser     | ![Image not found!](resources/fashion_mnist_sprite_1.png) |\n",
    "| 2        | Pullover    | ![Image not found!](resources/fashion_mnist_sprite_2.png) |\n",
    "| 3        | Dress       | ![Image not found!](resources/fashion_mnist_sprite_3.png) |\n",
    "| 4        | Coat        | ![Image not found!](resources/fashion_mnist_sprite_4.png) |\n",
    "| 5        | Sandal      | ![Image not found!](resources/fashion_mnist_sprite_5.png) |\n",
    "| 6        | Shirt       | ![Image not found!](resources/fashion_mnist_sprite_6.png) |\n",
    "| 7        | Sneaker     | ![Image not found!](resources/fashion_mnist_sprite_7.png) |\n",
    "| 8        | Bag         | ![Image not found!](resources/fashion_mnist_sprite_8.png) |\n",
    "| 9        | Ankle boot  | ![Image not found!](resources/fashion_mnist_sprite_9.png) |\n",
    "\n",
    "<p>Below you can see a table with all $70000$ samples (we start to count at 0). Remember, tabular data can have columns in various data types. In our case, the $784$ features (the pixels) are given in floating point numbers (recall <i>primitive data types</i>). We would refer to the fashion item type as a <i>label</i>, <i>target</i> or <i>class</i> rather than a feature, because we want to predict the fashion item type using all the (pixel) features.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "different-corrections",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>item_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1         0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0     0.0   \n",
       "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    33.0   \n",
       "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0  ...     114.0     130.0      76.0       0.0       0.0   \n",
       "2         22.0  ...       0.0       1.0       0.0       0.0       0.0   \n",
       "3         96.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69996     31.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  pixel784  item_type  \n",
       "0           0.0       0.0       0.0       0.0          9  \n",
       "1           0.0       0.0       0.0       0.0          0  \n",
       "2           0.0       0.0       0.0       0.0          0  \n",
       "3           0.0       0.0       0.0       0.0          3  \n",
       "4           0.0       0.0       0.0       0.0          0  \n",
       "...         ...       ...       ...       ...        ...  \n",
       "69995       0.0       0.0       0.0       0.0          9  \n",
       "69996       0.0       0.0       0.0       0.0          1  \n",
       "69997       0.0       0.0       0.0       0.0          8  \n",
       "69998       0.0       0.0       0.0       0.0          1  \n",
       "69999       0.0       0.0       0.0       0.0          5  \n",
       "\n",
       "[70000 rows x 785 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fashion_mnist = u2.load_fashion_mnist()\n",
    "data_fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-minnesota",
   "metadata": {},
   "source": [
    "<p>Before we can start with analyzing the gradient flow of a neural network, we have to split our data set into a <i>training set</i> and into a <i>test set</i>. The procedure was discussed during the last unit, so more information may be found in the accompanying lecture notes.\n",
    "\n",
    "<p>We now divide the data set between the training set and the test set in a ratio of $2:1$. Note that the train-test split is performed randomly meaning that by execution of the command, the chance that a sample lands in the training (test) set is a prior given by the split ratio. Therefore, we will hardly obtain the same training (test) data set again using a different random seed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "canadian-ribbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Full data set is of size: 70000\n",
      "Training subset is of size: 46666\n",
      " Testing subset is of size: 23334\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility.\n",
    "u2.set_seed(0)\n",
    "\n",
    "# Split the Fashion-MNIST data set into training as well as test set and print their respective size.\n",
    "data_fashion_mnist_train, data_fashion_mnist_test = u2.split_data(data_fashion_mnist, test_size=1.0 / 3.0)\n",
    "print(f'  Full data set is of size: {data_fashion_mnist.shape[0]:>5}')\n",
    "print(f'Training subset is of size: {data_fashion_mnist_train.shape[0]:>5}')\n",
    "print(f' Testing subset is of size: {data_fashion_mnist_test.shape[0]:>5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-wound",
   "metadata": {},
   "source": [
    "<p>Before actually training a neural network on Fashion-MNIST data for a gradient-flow analysis, we have to pre-process the images in order to have them in the correct shape. For this very purpose, we are creating two <code>TensorDataset</code> instances, which are encapsulated in a separate <code>Dataloader</code> instance for the <i>training</i> as well as <i>test</i> data set.</p>\n",
    "\n",
    "<p>As the definitions of <code>loader_fashion_mnist_train</code> and <code>loader_fashion_mnist_test</code> might be a little bit intimidating at a first glance, it is always a good idea to keep an eye on the corresponding documentation – <a href=\"https://pytorch.org/docs/stable/data.html?highlight=tensordataset#torch.utils.data.TensorDataset\">TensorDataset</a> and <a href=\"https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader\">DataLoader</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader for iterating the Fashion-MNIST training data set.\n",
    "loader_fashion_mnist_train = torch.utils.data.DataLoader(\n",
    "    dataset=torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(data_fashion_mnist_train.drop(columns=['item_type']).values / 255),  # normalize to range [0; 1]\n",
    "        torch.from_numpy(data_fashion_mnist_train['item_type'].values)\n",
    "    ),\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create data loader for iterating the Fashion-MNIST test data set.\n",
    "loader_fashion_mnist_test = torch.utils.data.DataLoader(\n",
    "    dataset=torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(data_fashion_mnist_test.drop(columns=['item_type']).values / 255),  # normalize to range [0; 1]\n",
    "        torch.from_numpy(data_fashion_mnist_test['item_type'].values)\n",
    "    ),\n",
    "    batch_size=128,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-episode",
   "metadata": {},
   "source": [
    "<a name=\"training-neural-network\"></a><h2>Training of a Neural Network</h2>\n",
    "<p>We feed the input vector $\\mathbf{x}_i$ ($28\\times{}28 = 784$ pixels) into the neural network (NN) and receive the output NN($\\mathbf{x}_i; \\mathbf{W}) = \\hat{y}$. In this case, the output is a vector with $K = 10$ entries. Using the softmax function, for the 10 classes $y \\in {0, \\ldots, 9}$, the entries are the probabilities of NN($\\mathbf{x}_i; \\mathbf{W}$) belonging to class $k$:</p>\n",
    "\n",
    "<p>\n",
    "    \\begin{equation}\n",
    "        p(y=k|\\mathbf{x}_i) = \\frac{e^{\\text{NN}_k(\\mathbf{x}_i;\\mathbf{W})}}{\\sum_{K} e^{\\text{NN}_j(\\mathbf{x}_i;\\mathbf{W})}}\n",
    "    \\end{equation}\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-savings",
   "metadata": {},
   "source": [
    "<a name=\"forward-pass\"></a><h3 style=\"color:rgb(0,120,170)\">Forward pass</h3>\n",
    "<img src=\"resources/forward.gif\" alt=\"Image not found!\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-sleeping",
   "metadata": {},
   "source": [
    "<p>Neural networks are nested structures, and can therefore be written down as a nested formula – although graphical representations, like the ones in this section, often help to better grasp what is going on. Nonetheless, the neural network, as depicted above, can be represented by:\n",
    "<center>\n",
    "    \\begin{equation}\n",
    "        \\hat{y} = g\\left(h^{(3)}(h^{(2)}(h^{(1)}(\\mathbf{x};\\mathbf{W}_1);\\mathbf{W}_2);\\mathbf{W}_3);\\mathbf{W}_4 \\right )\n",
    "    \\end{equation}\n",
    "</center>\n",
    "\n",
    "The graphical representation below depicts the computation of a fully connected layer – in this case, the <i>input</i> layer (bias not shown for simplicity reasons):</p>\n",
    "\n",
    "<table>\n",
    "    <td><img src=\"resources/forward_layers.png\" alt=\"Image not found!\"/></td>\n",
    "    <td><img src=\"resources/forward_matrices.png\" alt=\"Image not found!\"/></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-offer",
   "metadata": {},
   "source": [
    "<a name=\"backward-pass\"></a><h3 style=\"color:rgb(0,120,170)\">Backward pass</h3>\n",
    "<p>We want $\\hat{y}$ to be as close as possible to the true target value $y$. Hence, we apply a loss function $L(y,\\hat{y})$ to measure how close our predictions $\\hat{y}$ are to the true target $y$. Generally speaking, the smaller the loss, the better the prediction. To compute the gradients with respect to all parameters of the network, the error gets backpropagated from the network output (or from the corresponding loss function, to be precise) to the input by application of the <i>chain rule</i>:\n",
    "\n",
    "<center>\n",
    "    \\begin{align*}\n",
    "        \\mathbf{W}_4 & \\leftarrow \\mathbf{W}_4 - \\eta \\frac{\\partial L}{\\partial \\mathbf{W}_4} \\\\\n",
    "        \\mathbf{W}_3 & \\leftarrow \\mathbf{W}_3 - \\eta \\frac{\\partial L}{\\partial h^{(3)}}\\frac{\\partial h^{(3)}}{\\partial \\mathbf{W}_3} \\\\\n",
    "        \\mathbf{W}_2 & \\leftarrow \\mathbf{W}_2 - \\eta \\frac{\\partial L}{\\partial h^{(3)}}\\frac{\\partial h^{(3)}}{\\partial h^{(2)}}\\frac{\\partial h^{(2)}}{\\partial \\mathbf{W}_2} \\\\\n",
    "        \\mathbf{W}_1 & \\leftarrow \\mathbf{W}_1 - \\eta \\frac{\\partial L}{\\partial h^{(3)}}\\frac{\\partial h^{(3)}}{\\partial h^{(2)}}\\frac{\\partial h^{(2)}}{\\partial h^{(1)}}\\frac{\\partial h^{(1)}}{\\partial \\mathbf{W}_1}\n",
    "    \\end{align*}\n",
    "</center>\n",
    "    \n",
    "The graphical representation below depicts the flow of the error singal through the network – starting at the output and directed to the input.</p>\n",
    "\n",
    "<img src=\"resources/backward.gif\" alt=\"Image not found!\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-patrol",
   "metadata": {},
   "source": [
    "<a name=\"logistic-regression\"></a><h2>Vanishing Gradients in Logistic Regression</h2>\n",
    "<p>As discussed in Hands-on AI I, <i>Logistic Regression</i> is a relatively simple model. It consists of only one weight matrix $\\mathbf{W}$ which maps the input vector to the pre-activated output. In the simplest case, the pre-activated output is activated by a <i>logistic function</i> (hence the name), often simply termed <i>sigmoid</i>.</p>\n",
    "\n",
    "<p><b>Note: In the following code snippets, you do not have to worry about the activation function in the output layer and also not about the loss function. Both are handled internally in the <code>u2_utils.py</code> file for numerical stability. Please keep in mind, if there are <i>multiple</i> classes (more than <i>two</i>) like in the Fashion-MNIST data set, it is sometimes called <i>Softmax Regression</i> since the logistic function at the output is replaced by the <i>softmax</i> function.</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "atlantic-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model: torch.nn.Module, optimizer: torch.optim.Optimizer, num_epochs: int,\n",
    "                       loader_train: torch.utils.data.DataLoader, loader_test: torch.utils.data.DataLoader,\n",
    "                       device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')) -> None:\n",
    "    \"\"\"\n",
    "    Auxiliary function for training and evaluating a corresponding model.\n",
    "    \n",
    "    :param model: model instance to train and evaluate\n",
    "    :param optimizer: optimizer to use for model training\n",
    "    :param num_epochs: amount of epochs for model training\n",
    "    :param loader_train: data loader supplying the training samples\n",
    "    :param loader_test: data loader supplying the test samples\n",
    "    :param device: device to use for model training and evaluation\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train model instance for one epoch.\n",
    "        u2.train_network(\n",
    "            model=model,\n",
    "            data_loader=loader_train,\n",
    "            device=device,\n",
    "            optimizer=optimizer\n",
    "        )\n",
    "\n",
    "        # Evaluate current model instance.\n",
    "        performance = u2.test_network(\n",
    "            model=model,\n",
    "            data_loader=loader_train,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Print result of current epoch to standard out.\n",
    "        print(f'Epoch: {str(epoch + 1).zfill(len(str(num_epochs)))} ' +\n",
    "              f'/ Train loss: {performance[0]:.4f} / Train accuracy: {performance[1]:.4f}')\n",
    "\n",
    "    # Evaluate final model on test data set.\n",
    "    performance = u2.test_network(model=model, data_loader=loader_test, device=device)\n",
    "    print(f'\\nTest loss: {performance[0]:.4f} / Test accuracy: {performance[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-consumer",
   "metadata": {},
   "source": [
    "After defining an auxiliary function for training and evaluating a specified model (we will use this functionality more often in this unit, hence separating it in a corresponding function does make sense), we will create and train a <i>single layer</i> logistic regression model (0 hidden layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "compound-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression0H(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Logistic regression tailored to process Fashion-MNIST data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "gothic-yorkshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression0H(\n",
      "  (fc1): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility.\n",
    "u2.set_seed(0)\n",
    "\n",
    "# Create LogisticRegression instance and the corresponding optimizer to use.\n",
    "logistic_regression_model = LogisticRegression0H()\n",
    "optimizer = torch.optim.SGD(logistic_regression_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Show the architecture of the logistic regression model.\n",
    "print(logistic_regression_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "charitable-heath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / Train loss: 0.0137 / Train accuracy: 0.5776\n",
      "Epoch: 2 / Train loss: 0.0114 / Train accuracy: 0.6449\n",
      "Epoch: 3 / Train loss: 0.0101 / Train accuracy: 0.6591\n",
      "\n",
      "Test loss: 0.0102 / Test accuracy: 0.6512\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility.\n",
    "u2.set_seed(0)\n",
    "\n",
    "# Train and evaluate LogisticRegression instance on the Fashion-MNIST training set.\n",
    "train_and_evaluate(\n",
    "    model=logistic_regression_model,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=3,\n",
    "    loader_train=loader_fashion_mnist_train,\n",
    "    loader_test=loader_fashion_mnist_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-prime",
   "metadata": {},
   "source": [
    "<a name=\"adding-hidden-layer-one\"></a><h3 style=\"color:rgb(0,120,170)\">Adding a hidden layer</h3>\n",
    "Common knowledge suggests to add a fully connected layer as a hidden one to increase the performance of the network. Hence, we are rewriting the previous implementation of <code>LogisticRegression</code> to include said hidden layer – for simplicity, the amount of output neurons of the input layer should be the same as its input size (this results in a <i>square</i> weight matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "configured-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression1H(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Logistic regression tailored to process Fashion-MNIST data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, 28 * 28)\n",
    "        self.ac1 = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(self.fc1.out_features, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "infrared-segment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression1H(\n",
      "  (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (ac1): Sigmoid()\n",
      "  (fc2): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility.\n",
    "u2.set_seed(0)\n",
    "\n",
    "# Create LogisticRegression instance and the corresponding optimizer to use.\n",
    "logistic_regression_model = LogisticRegression1H()\n",
    "optimizer = torch.optim.SGD(logistic_regression_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Show the architecture of the logistic regression model.\n",
    "print(logistic_regression_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "shaped-inflation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / Train loss: 0.0177 / Train accuracy: 0.4221\n",
      "Epoch: 2 / Train loss: 0.0174 / Train accuracy: 0.4553\n",
      "Epoch: 3 / Train loss: 0.0171 / Train accuracy: 0.5152\n",
      "\n",
      "Test loss: 0.0171 / Test accuracy: 0.5108\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility.\n",
    "u2.set_seed(0)\n",
    "\n",
    "# Train and evaluate LogisticRegression instance on the Fashion-MNIST training set.\n",
    "train_and_evaluate(\n",
    "    model=logistic_regression_model,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=3,\n",
    "    loader_train=loader_fashion_mnist_train,\n",
    "    loader_test=loader_fashion_mnist_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-resolution",
   "metadata": {},
   "source": [
    "<a name=\"adding-hidden-layer-two\"></a><h3 style=\"color:rgb(0,120,170)\">Adding a second hidden layer</h3>\n",
    "Adding an additional layer unfortunately did <i>not</i> improve the performance. Maybe we were just unlucky, so let's add <i>another</i> layer. Therefore, we are once again rewriting the previous implementation of <code>LogisticRegression</code> to include the <i>second</i> hidden layer. For simplicity reasons, the amount of output neurons of the first hidden layer stays the same as its input size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "educational-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression2H(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Logistic regression tailored to process Fashion-MNIST data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, 28 * 28)\n",
    "        self.ac1 = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(self.fc1.out_features, self.fc1.out_features)\n",
    "        self.ac2 = torch.nn.Sigmoid()\n",
    "        self.fc3 = torch.nn.Linear(self.fc2.out_features, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ac2(x)\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "powered-theme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression2H(\n",
      "  (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (ac1): Sigmoid()\n",
      "  (fc2): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (ac2): Sigmoid()\n",
      "  (fc3): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility.\n",
    "u2.set_seed(0)\n",
    "\n",
    "# Create LogisticRegression instance and the corresponding optimizer to use.\n",
    "logistic_regression_model = LogisticRegression2H()\n",
    "optimizer = torch.optim.SGD(logistic_regression_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Show the architecture of the logistic regression model.\n",
    "print(logistic_regression_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "endangered-seven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / Train loss: 0.0180 / Train accuracy: 0.1008\n",
      "Epoch: 2 / Train loss: 0.0180 / Train accuracy: 0.1020\n",
      "Epoch: 3 / Train loss: 0.0180 / Train accuracy: 0.1983\n",
      "\n",
      "Test loss: 0.0180 / Test accuracy: 0.1907\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility.\n",
    "u2.set_seed(0)\n",
    "\n",
    "# Train and evaluate LogisticRegression instance on the Fashion-MNIST training set.\n",
    "train_and_evaluate(\n",
    "    model=logistic_regression_model,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=3,\n",
    "    loader_train=loader_fashion_mnist_train,\n",
    "    loader_test=loader_fashion_mnist_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-individual",
   "metadata": {},
   "source": [
    "<a name=\"adding-hidden-layer-three\"></a><h3 style=\"color:rgb(0,120,170)\">Adding a third hidden layer</h3>\n",
    "Again, the additional hidden layer did <i>not</i> deliver the expected performance gain. Maybe it is simply by coincidence due to weight initialization or other factors. Hence, we are rewriting the previous implementation of <code>LogisticRegression</code> one last time to include a <i>third</i> hidden layer – the weight matrix of the second hidden layer should again be square, identical to the first hidden layer. This time, we are increasing the network performance – for sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "funky-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression3H(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Logistic regression tailored to process Fashion-MNIST data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, 28 * 28)\n",
    "        self.ac1 = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(self.fc1.out_features, self.fc1.out_features)\n",
    "        self.ac2 = torch.nn.Sigmoid()\n",
    "        self.fc3 = torch.nn.Linear(self.fc2.out_features, self.fc2.out_features)\n",
    "        self.ac3 = torch.nn.Sigmoid()\n",
    "        self.fc4 = torch.nn.Linear(self.fc3.out_features, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ac2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.ac3(x)\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "verbal-figure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression3H(\n",
      "  (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (ac1): Sigmoid()\n",
      "  (fc2): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (ac2): Sigmoid()\n",
      "  (fc3): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (ac3): Sigmoid()\n",
      "  (fc4): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility.\n",
    "u2.set_seed(0)\n",
    "\n",
    "# Create LogisticRegression instance and the corresponding optimizer to use.\n",
    "logistic_regression_model = LogisticRegression3H()\n",
    "optimizer = torch.optim.SGD(logistic_regression_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Show the architecture of the logistic regression model.\n",
    "print(logistic_regression_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "uniform-jesus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / Train loss: 0.0180 / Train accuracy: 0.1007\n",
      "Epoch: 2 / Train loss: 0.0180 / Train accuracy: 0.1020\n",
      "Epoch: 3 / Train loss: 0.0180 / Train accuracy: 0.1024\n",
      "\n",
      "Test loss: 0.0181 / Test accuracy: 0.0965\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility.\n",
    "u2.set_seed(0)\n",
    "\n",
    "# Train and evaluate LogisticRegression instance on the Fashion-MNIST training set.\n",
    "train_and_evaluate(\n",
    "    model=logistic_regression_model,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=3,\n",
    "    loader_train=loader_fashion_mnist_train,\n",
    "    loader_test=loader_fashion_mnist_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-stage",
   "metadata": {},
   "source": [
    "<a name=\"logistic-regression-gradients\"></a><h3 style=\"color:rgb(0,120,170)\">Analyzing gradients</h3>\n",
    "<p>As the previous examples showed, naively stacking layers does often <i>not</i> lead to the expected results. The reason for this specific behavior is the <i>Vanishing Gradient</i>. For this very reason, we are now collecting and visualizing the magnitudes of the weight parameter gradients of the different logistic regression models.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "frequent-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_gradients(model: torch.nn.Module, loader: torch.utils.data.DataLoader,\n",
    "                      device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')) -> Sequence[Dict[str, np.array]]:\n",
    "    \"\"\"\n",
    "    Auxiliary function for collecting gradients of a corresponding model.\n",
    "    \n",
    "    :param model: model instance to be used for collecting gradients\n",
    "    :param loader: data loader supplying the samples used for collecting gradients\n",
    "    :param device: device to use for gradient collection\n",
    "    :return: sequence of parameter names and gradients, averaged over all parameter elements\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model_state = model.training\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Iterating over the data set and computing the corresponding gradients.\n",
    "    # Since we are only interested in the gradients, we can skip the optimization step.\n",
    "    gradients = {}\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    for data, target in loader:\n",
    "        data, target = data.float().to(device), target.long().to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "    \n",
    "        # Collecting the (averaged absolute) gradients from the current model.\n",
    "        for name, parameter in model.named_parameters():\n",
    "            if \"weight\" in name and parameter.grad is not None:\n",
    "                gradients.setdefault(name, []).append(parameter.grad.view(-1).abs().mean().item())\n",
    "        model.zero_grad()\n",
    "    \n",
    "    # Reset model state and return collected gradients.\n",
    "    model.train(mode=model_state)\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-hygiene",
   "metadata": {},
   "source": [
    "<p>After defining an auxiliary function for collecting gradients of a specified model (we will use this functionality more often in this unit, hence separating it in a corresponding function does make sense), we will create a <i>new</i> instance of each logistic regression model for further analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "polish-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for model_class in [LogisticRegression0H, LogisticRegression1H, LogisticRegression2H, LogisticRegression3H]:\n",
    "    # Set random seed for reproducibility.\n",
    "    u2.set_seed(0)\n",
    "    \n",
    "    # Create logistic regression models.\n",
    "    models.append(model_class())\n",
    "\n",
    "gradients = [(model, collect_gradients(model=model, loader=loader_fashion_mnist_train)) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f861d620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression0H(\n",
       "    (fc1): Linear(in_features=784, out_features=10, bias=True)\n",
       "  ),\n",
       "  {'fc1.weight': [0.017668552696704865,\n",
       "    0.016581552103161812,\n",
       "    0.01682390086352825,\n",
       "    0.016999216750264168,\n",
       "    0.0159895196557045,\n",
       "    0.014617166481912136,\n",
       "    0.017019173130393028,\n",
       "    0.01598213240504265,\n",
       "    0.016535768285393715,\n",
       "    0.01560235396027565,\n",
       "    0.015096482820808887,\n",
       "    0.017171291634440422,\n",
       "    0.016558533534407616,\n",
       "    0.016267456114292145,\n",
       "    0.01639590784907341,\n",
       "    0.017879460006952286,\n",
       "    0.017759937793016434,\n",
       "    0.017321724444627762,\n",
       "    0.01460819598287344,\n",
       "    0.016865946352481842,\n",
       "    0.0172385536134243,\n",
       "    0.016807833686470985,\n",
       "    0.018713731318712234,\n",
       "    0.0196696650236845,\n",
       "    0.019688159227371216,\n",
       "    0.016215074807405472,\n",
       "    0.019573668017983437,\n",
       "    0.018442649394273758,\n",
       "    0.014378516934812069,\n",
       "    0.01617014966905117,\n",
       "    0.016611995175480843,\n",
       "    0.01814083941280842,\n",
       "    0.017466900870203972,\n",
       "    0.017080364748835564,\n",
       "    0.01622553914785385,\n",
       "    0.017795566469430923,\n",
       "    0.01659199595451355,\n",
       "    0.020134247839450836,\n",
       "    0.01526300422847271,\n",
       "    0.01616078056395054,\n",
       "    0.01738448441028595,\n",
       "    0.015205028466880322,\n",
       "    0.017921537160873413,\n",
       "    0.016505835577845573,\n",
       "    0.017635418102145195,\n",
       "    0.019911989569664,\n",
       "    0.017928821966052055,\n",
       "    0.01696747913956642,\n",
       "    0.015501727350056171,\n",
       "    0.01419953815639019,\n",
       "    0.017879605293273926,\n",
       "    0.01773333176970482,\n",
       "    0.01799880899488926,\n",
       "    0.017104674130678177,\n",
       "    0.017973456531763077,\n",
       "    0.01805853471159935,\n",
       "    0.020519785583019257,\n",
       "    0.016143057495355606,\n",
       "    0.016598930582404137,\n",
       "    0.019062589854002,\n",
       "    0.016996486112475395,\n",
       "    0.015015014447271824,\n",
       "    0.019407616928219795,\n",
       "    0.016920678317546844,\n",
       "    0.01791994273662567,\n",
       "    0.016910400241613388,\n",
       "    0.016390331089496613,\n",
       "    0.01579068787395954,\n",
       "    0.017903432250022888,\n",
       "    0.015997152775526047,\n",
       "    0.016833340749144554,\n",
       "    0.017088284716010094,\n",
       "    0.01729488931596279,\n",
       "    0.01658400520682335,\n",
       "    0.016774214804172516,\n",
       "    0.01653858833014965,\n",
       "    0.01886705309152603,\n",
       "    0.017617592588067055,\n",
       "    0.01797501929104328,\n",
       "    0.02012619748711586,\n",
       "    0.015492772683501244,\n",
       "    0.019291309639811516,\n",
       "    0.019320828840136528,\n",
       "    0.015869852155447006,\n",
       "    0.01658385805785656,\n",
       "    0.017686136066913605,\n",
       "    0.016301365569233894,\n",
       "    0.015317278914153576,\n",
       "    0.018125401809811592,\n",
       "    0.015870405361056328,\n",
       "    0.0165255106985569,\n",
       "    0.014280521310865879,\n",
       "    0.015051850117743015,\n",
       "    0.015516666695475578,\n",
       "    0.016108304262161255,\n",
       "    0.018980830907821655,\n",
       "    0.01597350463271141,\n",
       "    0.018287094309926033,\n",
       "    0.01687115803360939,\n",
       "    0.01704520359635353,\n",
       "    0.019261300563812256,\n",
       "    0.01619185507297516,\n",
       "    0.017877282574772835,\n",
       "    0.014773634262382984,\n",
       "    0.019033856689929962,\n",
       "    0.01712336763739586,\n",
       "    0.01782255619764328,\n",
       "    0.014281902462244034,\n",
       "    0.019206993281841278,\n",
       "    0.020596101880073547,\n",
       "    0.01790076680481434,\n",
       "    0.016039418056607246,\n",
       "    0.015539565123617649,\n",
       "    0.018401138484477997,\n",
       "    0.019289139658212662,\n",
       "    0.01617850735783577,\n",
       "    0.02049611322581768,\n",
       "    0.017767446115612984,\n",
       "    0.016125835478305817,\n",
       "    0.017165236175060272,\n",
       "    0.019448595121502876,\n",
       "    0.01558309979736805,\n",
       "    0.0170628372579813,\n",
       "    0.016714731231331825,\n",
       "    0.015054125338792801,\n",
       "    0.016127033159136772,\n",
       "    0.017114650458097458,\n",
       "    0.014995270408689976,\n",
       "    0.018745962530374527,\n",
       "    0.017428776249289513,\n",
       "    0.01746371202170849,\n",
       "    0.01638241671025753,\n",
       "    0.01768886111676693,\n",
       "    0.014791171066462994,\n",
       "    0.018047800287604332,\n",
       "    0.01732354797422886,\n",
       "    0.0173609908670187,\n",
       "    0.017245734110474586,\n",
       "    0.018585456535220146,\n",
       "    0.018775226548314095,\n",
       "    0.015488333068788052,\n",
       "    0.015740232542157173,\n",
       "    0.017394697293639183,\n",
       "    0.016246698796749115,\n",
       "    0.01740802265703678,\n",
       "    0.016899090260267258,\n",
       "    0.017557192593812943,\n",
       "    0.019717883318662643,\n",
       "    0.017845604568719864,\n",
       "    0.015328185632824898,\n",
       "    0.01555468887090683,\n",
       "    0.019254080951213837,\n",
       "    0.01703277975320816,\n",
       "    0.01747504249215126,\n",
       "    0.018202470615506172,\n",
       "    0.016951147466897964,\n",
       "    0.016180651262402534,\n",
       "    0.01694619655609131,\n",
       "    0.015967169776558876,\n",
       "    0.016154753044247627,\n",
       "    0.016603952273726463,\n",
       "    0.01749822124838829,\n",
       "    0.016286615282297134,\n",
       "    0.01853741705417633,\n",
       "    0.01816518045961857,\n",
       "    0.016593148931860924,\n",
       "    0.017579227685928345,\n",
       "    0.02059134468436241,\n",
       "    0.017579972743988037,\n",
       "    0.014935257844626904,\n",
       "    0.019852861762046814,\n",
       "    0.016299843788146973,\n",
       "    0.01510125957429409,\n",
       "    0.016480401158332825,\n",
       "    0.019701993092894554,\n",
       "    0.015385414473712444,\n",
       "    0.018232209607958794,\n",
       "    0.017649829387664795,\n",
       "    0.015486590564250946,\n",
       "    0.01830224320292473,\n",
       "    0.01724637858569622,\n",
       "    0.01924479752779007,\n",
       "    0.016848910599946976,\n",
       "    0.01751679740846157,\n",
       "    0.01857711374759674,\n",
       "    0.015709111467003822,\n",
       "    0.016995202749967575,\n",
       "    0.018971340730786324,\n",
       "    0.01670408435165882,\n",
       "    0.017461154609918594,\n",
       "    0.016720401123166084,\n",
       "    0.016131266951560974,\n",
       "    0.016711952164769173,\n",
       "    0.018529940396547318,\n",
       "    0.016958467662334442,\n",
       "    0.016637692227959633,\n",
       "    0.015770060941576958,\n",
       "    0.02033963054418564,\n",
       "    0.01846497505903244,\n",
       "    0.015428056940436363,\n",
       "    0.01620807684957981,\n",
       "    0.01611466333270073,\n",
       "    0.019625423476099968,\n",
       "    0.01999204233288765,\n",
       "    0.017888136208057404,\n",
       "    0.02018756791949272,\n",
       "    0.014526166021823883,\n",
       "    0.01671023666858673,\n",
       "    0.015477747656404972,\n",
       "    0.01688617840409279,\n",
       "    0.020625412464141846,\n",
       "    0.014982014894485474,\n",
       "    0.022114546969532967,\n",
       "    0.016823306679725647,\n",
       "    0.020791862159967422,\n",
       "    0.01923403888940811,\n",
       "    0.017038986086845398,\n",
       "    0.020280582830309868,\n",
       "    0.01687891036272049,\n",
       "    0.018722767010331154,\n",
       "    0.01635534130036831,\n",
       "    0.015567350201308727,\n",
       "    0.016583489254117012,\n",
       "    0.01934683695435524,\n",
       "    0.017533907666802406,\n",
       "    0.017390627413988113,\n",
       "    0.018484344705939293,\n",
       "    0.017308667302131653,\n",
       "    0.014665485359728336,\n",
       "    0.016232352703809738,\n",
       "    0.016736948862671852,\n",
       "    0.017937345430254936,\n",
       "    0.017260674387216568,\n",
       "    0.016100693494081497,\n",
       "    0.014821414835751057,\n",
       "    0.01819108985364437,\n",
       "    0.01964118331670761,\n",
       "    0.01756308414041996,\n",
       "    0.019234735518693924,\n",
       "    0.017099963501095772,\n",
       "    0.016279859468340874,\n",
       "    0.016443146392703056,\n",
       "    0.016992293298244476,\n",
       "    0.015222939662635326,\n",
       "    0.016970194876194,\n",
       "    0.015215865336358547,\n",
       "    0.015550022944808006,\n",
       "    0.015050430782139301,\n",
       "    0.018632939085364342,\n",
       "    0.014817916788160801,\n",
       "    0.018616342917084694,\n",
       "    0.019514286890625954,\n",
       "    0.015921302139759064,\n",
       "    0.015466575510799885,\n",
       "    0.014609147794544697,\n",
       "    0.014840609394013882,\n",
       "    0.014562604017555714,\n",
       "    0.016646858304739,\n",
       "    0.020489484071731567,\n",
       "    0.018120989203453064,\n",
       "    0.017729414626955986,\n",
       "    0.016116157174110413,\n",
       "    0.015377630479633808,\n",
       "    0.016260391101241112,\n",
       "    0.01628885045647621,\n",
       "    0.016823073849081993,\n",
       "    0.015265840105712414,\n",
       "    0.018551168963313103,\n",
       "    0.01663891412317753,\n",
       "    0.015160027891397476,\n",
       "    0.015642929822206497,\n",
       "    0.016037635505199432,\n",
       "    0.017454493790864944,\n",
       "    0.018809271976351738,\n",
       "    0.018089165911078453,\n",
       "    0.016069399192929268,\n",
       "    0.019626060500741005,\n",
       "    0.016582028940320015,\n",
       "    0.017363376915454865,\n",
       "    0.016218505799770355,\n",
       "    0.016668597236275673,\n",
       "    0.017595767974853516,\n",
       "    0.018086789175868034,\n",
       "    0.017444021999835968,\n",
       "    0.01598438248038292,\n",
       "    0.017145898193120956,\n",
       "    0.018494483083486557,\n",
       "    0.01710743084549904,\n",
       "    0.014761977829039097,\n",
       "    0.015992915257811546,\n",
       "    0.019575562328100204,\n",
       "    0.01791737601161003,\n",
       "    0.015105696395039558,\n",
       "    0.016616353765130043,\n",
       "    0.014881874434649944,\n",
       "    0.018005821853876114,\n",
       "    0.019475385546684265,\n",
       "    0.0162954144179821,\n",
       "    0.01610550656914711,\n",
       "    0.01534850150346756,\n",
       "    0.01846213825047016,\n",
       "    0.016130484640598297,\n",
       "    0.016634797677397728,\n",
       "    0.01598074659705162,\n",
       "    0.015758614987134933,\n",
       "    0.016492269933223724,\n",
       "    0.017586316913366318,\n",
       "    0.017313942313194275,\n",
       "    0.015048249624669552,\n",
       "    0.01665276475250721,\n",
       "    0.018445385619997978,\n",
       "    0.01850048080086708,\n",
       "    0.016212990507483482,\n",
       "    0.016719894483685493,\n",
       "    0.016475683078169823,\n",
       "    0.019475746899843216,\n",
       "    0.017534911632537842,\n",
       "    0.018065398558974266,\n",
       "    0.017374582588672638,\n",
       "    0.01670244336128235,\n",
       "    0.01873447187244892,\n",
       "    0.016158275306224823,\n",
       "    0.01706477254629135,\n",
       "    0.0178518146276474,\n",
       "    0.015709014609456062,\n",
       "    0.016712594777345657,\n",
       "    0.017151137813925743,\n",
       "    0.017212068662047386,\n",
       "    0.015805697068572044,\n",
       "    0.016885727643966675,\n",
       "    0.018812334164977074,\n",
       "    0.0172133706510067,\n",
       "    0.01611838862299919,\n",
       "    0.01776263117790222,\n",
       "    0.01629038155078888,\n",
       "    0.016094518825411797,\n",
       "    0.0182208102196455,\n",
       "    0.018712826073169708,\n",
       "    0.01601744070649147,\n",
       "    0.015402537770569324,\n",
       "    0.01822936348617077,\n",
       "    0.015749508515000343,\n",
       "    0.016691328957676888,\n",
       "    0.016386838629841805,\n",
       "    0.01567085087299347,\n",
       "    0.01895899698138237,\n",
       "    0.014755009673535824,\n",
       "    0.017772115767002106,\n",
       "    0.01932556927204132,\n",
       "    0.01585000567138195,\n",
       "    0.017115650698542595,\n",
       "    0.017662620171904564,\n",
       "    0.01680346578359604,\n",
       "    0.01808774843811989,\n",
       "    0.016910525038838387,\n",
       "    0.018804382532835007,\n",
       "    0.017127277329564095,\n",
       "    0.017086131498217583,\n",
       "    0.017575249075889587,\n",
       "    0.017935197800397873,\n",
       "    0.017372719943523407,\n",
       "    0.01798924058675766,\n",
       "    0.01678801327943802,\n",
       "    0.01659146137535572,\n",
       "    0.020167537033557892]}),\n",
       " (LogisticRegression1H(\n",
       "    (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (ac1): Sigmoid()\n",
       "    (fc2): Linear(in_features=784, out_features=10, bias=True)\n",
       "  ),\n",
       "  {'fc1.weight': [0.0002762779768090695,\n",
       "    0.0002708359679672867,\n",
       "    0.000243931426666677,\n",
       "    0.00024659535847604275,\n",
       "    0.00026369845727458596,\n",
       "    0.00027394347125664353,\n",
       "    0.00026377802714705467,\n",
       "    0.0002392798342043534,\n",
       "    0.00027705408865585923,\n",
       "    0.0002587659109849483,\n",
       "    0.0002571563236415386,\n",
       "    0.00024037562252487987,\n",
       "    0.0002695900620892644,\n",
       "    0.0002686722727958113,\n",
       "    0.0002590106159914285,\n",
       "    0.0002860915847122669,\n",
       "    0.000273887999355793,\n",
       "    0.00026809226255863905,\n",
       "    0.0002711418201215565,\n",
       "    0.0002694873255677521,\n",
       "    0.00025064352666959167,\n",
       "    0.0003035715490113944,\n",
       "    0.000273076759185642,\n",
       "    0.0002661999606061727,\n",
       "    0.0002754140004981309,\n",
       "    0.00025847990764304996,\n",
       "    0.00024721529916860163,\n",
       "    0.00029022234957665205,\n",
       "    0.0003009830543305725,\n",
       "    0.0002610565861687064,\n",
       "    0.0002557593397796154,\n",
       "    0.00023580968263559043,\n",
       "    0.00028235616628080606,\n",
       "    0.0002941759012173861,\n",
       "    0.0002568727941252291,\n",
       "    0.00024650056730024517,\n",
       "    0.00029824592638760805,\n",
       "    0.0002515287196729332,\n",
       "    0.0002663334016688168,\n",
       "    0.00022727195755578578,\n",
       "    0.00027659692568704486,\n",
       "    0.00026588793843984604,\n",
       "    0.000295482313958928,\n",
       "    0.00027818221133202314,\n",
       "    0.00027165457140654325,\n",
       "    0.00029295121203176677,\n",
       "    0.00026131319464184344,\n",
       "    0.0002576186670921743,\n",
       "    0.00024791876785457134,\n",
       "    0.0002621107851155102,\n",
       "    0.00028191739693284035,\n",
       "    0.00026695342967286706,\n",
       "    0.0002628015645314008,\n",
       "    0.0002909095783252269,\n",
       "    0.00025807807105593383,\n",
       "    0.00024993359693326056,\n",
       "    0.00024658668553456664,\n",
       "    0.00025341787841171026,\n",
       "    0.0003418719279579818,\n",
       "    0.0002456151123624295,\n",
       "    0.00025311947683803737,\n",
       "    0.0002672386181075126,\n",
       "    0.0002876975340768695,\n",
       "    0.00027369652525521815,\n",
       "    0.0002688718668650836,\n",
       "    0.0002739827032200992,\n",
       "    0.00028591224690899253,\n",
       "    0.00027120974846184254,\n",
       "    0.0002789908612612635,\n",
       "    0.0002573465171735734,\n",
       "    0.000238366104895249,\n",
       "    0.0002531095524318516,\n",
       "    0.0002394219336565584,\n",
       "    0.00028514862060546875,\n",
       "    0.0002489408652763814,\n",
       "    0.00025395152624696493,\n",
       "    0.00025812003877945244,\n",
       "    0.0002485958975739777,\n",
       "    0.0002963499864563346,\n",
       "    0.00028624836704693735,\n",
       "    0.0002762806252576411,\n",
       "    0.0002843257097993046,\n",
       "    0.00034737191163003445,\n",
       "    0.00025027277297340333,\n",
       "    0.00030235841404646635,\n",
       "    0.0002738981565926224,\n",
       "    0.0002699178585316986,\n",
       "    0.00025373263633809984,\n",
       "    0.0002764001255854964,\n",
       "    0.00027775074704550207,\n",
       "    0.0002649106609169394,\n",
       "    0.00027643993962556124,\n",
       "    0.0002809359284583479,\n",
       "    0.00028231085161678493,\n",
       "    0.0002904512220993638,\n",
       "    0.0003025793412234634,\n",
       "    0.000295719743007794,\n",
       "    0.00023745129874441773,\n",
       "    0.0002484920260030776,\n",
       "    0.00025340341380797327,\n",
       "    0.00023374793818220496,\n",
       "    0.0002902622218243778,\n",
       "    0.0002838583604898304,\n",
       "    0.0002553535159677267,\n",
       "    0.000284014007775113,\n",
       "    0.0003064292250201106,\n",
       "    0.00030942526063881814,\n",
       "    0.00023978993704076856,\n",
       "    0.0002252300182590261,\n",
       "    0.0002684007922653109,\n",
       "    0.000278112362138927,\n",
       "    0.0002529997145757079,\n",
       "    0.0002828042197506875,\n",
       "    0.00026080769021064043,\n",
       "    0.00028400536393746734,\n",
       "    0.0002508588077034801,\n",
       "    0.0003074257110711187,\n",
       "    0.00026034523034468293,\n",
       "    0.0003025512269232422,\n",
       "    0.00030087781487964094,\n",
       "    0.0002967266773339361,\n",
       "    0.0002789021818898618,\n",
       "    0.00024321215460076928,\n",
       "    0.0002746862592175603,\n",
       "    0.00027185704675503075,\n",
       "    0.0002876506478060037,\n",
       "    0.0002602710737846792,\n",
       "    0.0002802170638460666,\n",
       "    0.0002646576031111181,\n",
       "    0.0002961477730423212,\n",
       "    0.00025675963843241334,\n",
       "    0.0002892416960094124,\n",
       "    0.00026194873498752713,\n",
       "    0.0002684677892830223,\n",
       "    0.00025971801369450986,\n",
       "    0.0002494208747521043,\n",
       "    0.0002839053049683571,\n",
       "    0.0002659585443325341,\n",
       "    0.00028468886739574373,\n",
       "    0.0002519475528970361,\n",
       "    0.0002743487129919231,\n",
       "    0.00023331020202022046,\n",
       "    0.0002698595926631242,\n",
       "    0.00027774894260801375,\n",
       "    0.00029163662111386657,\n",
       "    0.0002623434120323509,\n",
       "    0.0002689791435841471,\n",
       "    0.00025613143225200474,\n",
       "    0.00024243842926807702,\n",
       "    0.0002671265392564237,\n",
       "    0.0002569659554865211,\n",
       "    0.0002800256188493222,\n",
       "    0.00031107550603337586,\n",
       "    0.00024034158559516072,\n",
       "    0.00027243109070695937,\n",
       "    0.0002871887700166553,\n",
       "    0.00026586823514662683,\n",
       "    0.00022976026230026037,\n",
       "    0.000280210399068892,\n",
       "    0.000279930216493085,\n",
       "    0.00023921400133986026,\n",
       "    0.00028814325924031436,\n",
       "    0.00028064913931302726,\n",
       "    0.0002737360482569784,\n",
       "    0.00026237149722874165,\n",
       "    0.00026735561550594866,\n",
       "    0.00026781801716424525,\n",
       "    0.0002503198047634214,\n",
       "    0.00028336478862911463,\n",
       "    0.00025511375861242414,\n",
       "    0.0002563303569331765,\n",
       "    0.00027880759444087744,\n",
       "    0.000294615252641961,\n",
       "    0.00029933141195215285,\n",
       "    0.0002637612633407116,\n",
       "    0.00025422798353247344,\n",
       "    0.00027896344545297325,\n",
       "    0.00025970308342948556,\n",
       "    0.0002665948122739792,\n",
       "    0.0002471049374435097,\n",
       "    0.00027262739604339004,\n",
       "    0.0002448134764563292,\n",
       "    0.0002668365777935833,\n",
       "    0.00027506763581186533,\n",
       "    0.00027234130539000034,\n",
       "    0.0002666143118403852,\n",
       "    0.0002765145036391914,\n",
       "    0.0003090508689638227,\n",
       "    0.0003076281282119453,\n",
       "    0.0002458984963595867,\n",
       "    0.0002997007395606488,\n",
       "    0.00029984908178448677,\n",
       "    0.00022248820459935814,\n",
       "    0.0002980171993840486,\n",
       "    0.00029086603899486363,\n",
       "    0.00026240074657835066,\n",
       "    0.0002856867213267833,\n",
       "    0.0002474472566973418,\n",
       "    0.00030387655715458095,\n",
       "    0.0002568181080278009,\n",
       "    0.000272049946943298,\n",
       "    0.0002980276185553521,\n",
       "    0.0002721346390899271,\n",
       "    0.000260792498011142,\n",
       "    0.0002905448782257736,\n",
       "    0.0002952133072540164,\n",
       "    0.0002755382447503507,\n",
       "    0.00025546239339746535,\n",
       "    0.0002694882277864963,\n",
       "    0.00027416323428042233,\n",
       "    0.0002310253621544689,\n",
       "    0.00021557319269049913,\n",
       "    0.00024085775658022612,\n",
       "    0.00028570747235789895,\n",
       "    0.00025445822393521667,\n",
       "    0.00027993161347694695,\n",
       "    0.0002947606844827533,\n",
       "    0.0003073445404879749,\n",
       "    0.00027135416166856885,\n",
       "    0.0002813548198901117,\n",
       "    0.0002579384308774024,\n",
       "    0.0002568763738963753,\n",
       "    0.00024391402257606387,\n",
       "    0.00026454913313500583,\n",
       "    0.00027321960078552365,\n",
       "    0.0002740203053690493,\n",
       "    0.000285831541987136,\n",
       "    0.0002805815893225372,\n",
       "    0.00028533165459521115,\n",
       "    0.0002633442054502666,\n",
       "    0.00024692341685295105,\n",
       "    0.00022534494928549975,\n",
       "    0.00023359671467915177,\n",
       "    0.00026473047910258174,\n",
       "    0.00025296694366261363,\n",
       "    0.00030012501520104706,\n",
       "    0.00025296537205576897,\n",
       "    0.00026254195836372674,\n",
       "    0.0002692463749554008,\n",
       "    0.0002452208718750626,\n",
       "    0.0002666038926690817,\n",
       "    0.0002766375837381929,\n",
       "    0.00028705454315058887,\n",
       "    0.00026158863329328597,\n",
       "    0.00025654977071098983,\n",
       "    0.00028018988086842,\n",
       "    0.0003222532686777413,\n",
       "    0.0002864309644792229,\n",
       "    0.00024292862508445978,\n",
       "    0.00028276839293539524,\n",
       "    0.00030696045723743737,\n",
       "    0.000256912229815498,\n",
       "    0.00027421352569945157,\n",
       "    0.00026444648392498493,\n",
       "    0.00022121547954156995,\n",
       "    0.0002358548663323745,\n",
       "    0.000293329096166417,\n",
       "    0.00029764941427856684,\n",
       "    0.0002550313074607402,\n",
       "    0.00027365994174033403,\n",
       "    0.00024253375886473805,\n",
       "    0.00029097628430463374,\n",
       "    0.00027127808425575495,\n",
       "    0.0002725616213865578,\n",
       "    0.0002946087042801082,\n",
       "    0.0003122993221040815,\n",
       "    0.0002620753657538444,\n",
       "    0.000294576893793419,\n",
       "    0.0002668534580152482,\n",
       "    0.00024616383598186076,\n",
       "    0.00025932848802767694,\n",
       "    0.0002995588583871722,\n",
       "    0.00025389037909917533,\n",
       "    0.00030472324579022825,\n",
       "    0.0002987782936543226,\n",
       "    0.00026107998564839363,\n",
       "    0.0002689120883587748,\n",
       "    0.00025803493917919695,\n",
       "    0.0002542374422773719,\n",
       "    0.000287035945802927,\n",
       "    0.0002783500822260976,\n",
       "    0.0002814270555973053,\n",
       "    0.00027638525352813303,\n",
       "    0.00026927428552880883,\n",
       "    0.00023368874099105597,\n",
       "    0.00023978589160833508,\n",
       "    0.00025085906963795424,\n",
       "    0.00031543694785796106,\n",
       "    0.00022791909577790648,\n",
       "    0.0002445165882818401,\n",
       "    0.0003053101827390492,\n",
       "    0.0002376928023295477,\n",
       "    0.00030777830397710204,\n",
       "    0.00026822631480172276,\n",
       "    0.00024326333368662745,\n",
       "    0.000289912277366966,\n",
       "    0.0002646424691192806,\n",
       "    0.0002824368712026626,\n",
       "    0.00023937974765431136,\n",
       "    0.00022735378297511488,\n",
       "    0.00028345026657916605,\n",
       "    0.0002457396767567843,\n",
       "    0.00029175353120081127,\n",
       "    0.0002460191026329994,\n",
       "    0.0002178357681259513,\n",
       "    0.00025626004207879305,\n",
       "    0.0002481267147231847,\n",
       "    0.0002621141611598432,\n",
       "    0.00027826055884361267,\n",
       "    0.0002559445274528116,\n",
       "    0.00025049454416148365,\n",
       "    0.00025311403442174196,\n",
       "    0.0002965114254038781,\n",
       "    0.00027280833455733955,\n",
       "    0.0002853944606613368,\n",
       "    0.00024613607092760503,\n",
       "    0.00022738223196938634,\n",
       "    0.00026685482589527965,\n",
       "    0.0002408349100733176,\n",
       "    0.00030846637673676014,\n",
       "    0.0002737217291723937,\n",
       "    0.0003041343588847667,\n",
       "    0.00025856622960418463,\n",
       "    0.00026265185442753136,\n",
       "    0.0002571290242485702,\n",
       "    0.0002574824320618063,\n",
       "    0.00024253554875031114,\n",
       "    0.0002267394884256646,\n",
       "    0.00023205326579045504,\n",
       "    0.00026706320932134986,\n",
       "    0.0002624185581225902,\n",
       "    0.0002589881478343159,\n",
       "    0.00028002189355902374,\n",
       "    0.0002736056922003627,\n",
       "    0.00027402813429944217,\n",
       "    0.00029519066447392106,\n",
       "    0.0003049960359930992,\n",
       "    0.00030522546148858964,\n",
       "    0.0002671174006536603,\n",
       "    0.00029719341546297073,\n",
       "    0.000266588875092566,\n",
       "    0.0002903222048189491,\n",
       "    0.0003169369592797011,\n",
       "    0.0002663515624590218,\n",
       "    0.00024900410789996386,\n",
       "    0.0002651058603078127,\n",
       "    0.00025923841167241335,\n",
       "    0.00025496952002868056,\n",
       "    0.0002814483596011996,\n",
       "    0.0002792668528854847,\n",
       "    0.00025927426759153605,\n",
       "    0.0002959974517580122,\n",
       "    0.00025437105796299875,\n",
       "    0.0002882643020711839,\n",
       "    0.0003026858903467655,\n",
       "    0.0003034119727090001,\n",
       "    0.00024937608395703137,\n",
       "    0.00024399525136686862,\n",
       "    0.00025821663439273834,\n",
       "    0.0002894650970119983,\n",
       "    0.00026546118897385895,\n",
       "    0.0002677708107512444,\n",
       "    0.00029404519591480494,\n",
       "    0.0002570587384980172,\n",
       "    0.00029470358276739717],\n",
       "   'fc2.weight': [0.012018176726996899,\n",
       "    0.013887067325413227,\n",
       "    0.010132125578820705,\n",
       "    0.011534539982676506,\n",
       "    0.014750480651855469,\n",
       "    0.01509455218911171,\n",
       "    0.013431625440716743,\n",
       "    0.009681031107902527,\n",
       "    0.01775393821299076,\n",
       "    0.012145708315074444,\n",
       "    0.010028338991105556,\n",
       "    0.009081653319299221,\n",
       "    0.018483158200979233,\n",
       "    0.013836953788995743,\n",
       "    0.011578746140003204,\n",
       "    0.016892341896891594,\n",
       "    0.015817034989595413,\n",
       "    0.0146357836201787,\n",
       "    0.014782991260290146,\n",
       "    0.015667056664824486,\n",
       "    0.012516644783318043,\n",
       "    0.023034121841192245,\n",
       "    0.01238993275910616,\n",
       "    0.011187653057277203,\n",
       "    0.015132131054997444,\n",
       "    0.013837483711540699,\n",
       "    0.01504901610314846,\n",
       "    0.016745179891586304,\n",
       "    0.01367763802409172,\n",
       "    0.01692444458603859,\n",
       "    0.014546902850270271,\n",
       "    0.008602101355791092,\n",
       "    0.017649032175540924,\n",
       "    0.01834779605269432,\n",
       "    0.013944979757070541,\n",
       "    0.013698604889214039,\n",
       "    0.0202358178794384,\n",
       "    0.010708941146731377,\n",
       "    0.015228290110826492,\n",
       "    0.008896504528820515,\n",
       "    0.015274552628397942,\n",
       "    0.014835398644208908,\n",
       "    0.01742091029882431,\n",
       "    0.016839144751429558,\n",
       "    0.010812212713062763,\n",
       "    0.019569529220461845,\n",
       "    0.009177516214549541,\n",
       "    0.01331375353038311,\n",
       "    0.009719787165522575,\n",
       "    0.011356256902217865,\n",
       "    0.020024653524160385,\n",
       "    0.014718448743224144,\n",
       "    0.01653468795120716,\n",
       "    0.017261914908885956,\n",
       "    0.014549962244927883,\n",
       "    0.007577434182167053,\n",
       "    0.013709025457501411,\n",
       "    0.008812657557427883,\n",
       "    0.023564424365758896,\n",
       "    0.010952336713671684,\n",
       "    0.01198622677475214,\n",
       "    0.012424466200172901,\n",
       "    0.012895699590444565,\n",
       "    0.018374474719166756,\n",
       "    0.01099712960422039,\n",
       "    0.012816197238862514,\n",
       "    0.01709558628499508,\n",
       "    0.011743606999516487,\n",
       "    0.014943281188607216,\n",
       "    0.01214466243982315,\n",
       "    0.010187363252043724,\n",
       "    0.009092257358133793,\n",
       "    0.01143728382885456,\n",
       "    0.01798092946410179,\n",
       "    0.011563592590391636,\n",
       "    0.011039667762815952,\n",
       "    0.01342601515352726,\n",
       "    0.012679276056587696,\n",
       "    0.01759817637503147,\n",
       "    0.018092291429638863,\n",
       "    0.012549279257655144,\n",
       "    0.016743063926696777,\n",
       "    0.024542203173041344,\n",
       "    0.013739721849560738,\n",
       "    0.017271863296628,\n",
       "    0.020244348794221878,\n",
       "    0.01843426004052162,\n",
       "    0.01020439900457859,\n",
       "    0.012357360683381557,\n",
       "    0.018077347427606583,\n",
       "    0.013653961941599846,\n",
       "    0.013872821815311909,\n",
       "    0.015557165257632732,\n",
       "    0.015176361426711082,\n",
       "    0.016696644946932793,\n",
       "    0.019652804359793663,\n",
       "    0.018046259880065918,\n",
       "    0.009797342121601105,\n",
       "    0.011519134044647217,\n",
       "    0.01500392984598875,\n",
       "    0.013400476425886154,\n",
       "    0.01762722060084343,\n",
       "    0.01722310669720173,\n",
       "    0.01745026372373104,\n",
       "    0.01877407915890217,\n",
       "    0.01484051626175642,\n",
       "    0.018803298473358154,\n",
       "    0.009764393791556358,\n",
       "    0.010676652193069458,\n",
       "    0.015063421800732613,\n",
       "    0.016107255592942238,\n",
       "    0.01467434223741293,\n",
       "    0.011233525350689888,\n",
       "    0.013913491740822792,\n",
       "    0.01397266797721386,\n",
       "    0.012145888060331345,\n",
       "    0.016781168058514595,\n",
       "    0.014260435476899147,\n",
       "    0.013231107965111732,\n",
       "    0.017639946192502975,\n",
       "    0.020625771954655647,\n",
       "    0.016312645748257637,\n",
       "    0.014769631437957287,\n",
       "    0.010659058578312397,\n",
       "    0.014848869293928146,\n",
       "    0.01681109145283699,\n",
       "    0.012558721005916595,\n",
       "    0.015653058886528015,\n",
       "    0.014196432195603848,\n",
       "    0.017838861793279648,\n",
       "    0.01368618942797184,\n",
       "    0.01820215955376625,\n",
       "    0.01879865862429142,\n",
       "    0.01258525624871254,\n",
       "    0.014497238211333752,\n",
       "    0.009179124608635902,\n",
       "    0.014197085052728653,\n",
       "    0.01568572223186493,\n",
       "    0.014549712650477886,\n",
       "    0.01199090201407671,\n",
       "    0.015991931781172752,\n",
       "    0.010414586402475834,\n",
       "    0.014496232382953167,\n",
       "    0.015162232331931591,\n",
       "    0.015766648575663567,\n",
       "    0.014808197505772114,\n",
       "    0.013271373696625233,\n",
       "    0.014544653706252575,\n",
       "    0.02033810503780842,\n",
       "    0.013210155069828033,\n",
       "    0.010837662033736706,\n",
       "    0.013408339582383633,\n",
       "    0.017329923808574677,\n",
       "    0.013162179850041866,\n",
       "    0.016262369230389595,\n",
       "    0.016348985955119133,\n",
       "    0.014661137014627457,\n",
       "    0.008597895503044128,\n",
       "    0.014261096715927124,\n",
       "    0.014802753925323486,\n",
       "    0.012501920573413372,\n",
       "    0.016817407682538033,\n",
       "    0.01818202994763851,\n",
       "    0.01525912992656231,\n",
       "    0.008895963430404663,\n",
       "    0.01077540498226881,\n",
       "    0.016760773956775665,\n",
       "    0.01353955827653408,\n",
       "    0.01684502512216568,\n",
       "    0.013622053898870945,\n",
       "    0.009694493375718594,\n",
       "    0.01410660520195961,\n",
       "    0.016153432428836823,\n",
       "    0.019972456619143486,\n",
       "    0.015511946752667427,\n",
       "    0.011499425396323204,\n",
       "    0.01797349378466606,\n",
       "    0.010005466639995575,\n",
       "    0.016489703208208084,\n",
       "    0.009224706329405308,\n",
       "    0.016187334433197975,\n",
       "    0.009745094925165176,\n",
       "    0.0114878686144948,\n",
       "    0.013450141996145248,\n",
       "    0.01455899327993393,\n",
       "    0.01292875874787569,\n",
       "    0.014195832423865795,\n",
       "    0.015963353216648102,\n",
       "    0.01848423294723034,\n",
       "    0.011729729361832142,\n",
       "    0.01733243651688099,\n",
       "    0.0177717674523592,\n",
       "    0.014785373583436012,\n",
       "    0.015335340052843094,\n",
       "    0.02321479097008705,\n",
       "    0.014782974496483803,\n",
       "    0.014982614666223526,\n",
       "    0.01013876497745514,\n",
       "    0.017940953373908997,\n",
       "    0.005571551620960236,\n",
       "    0.014138296246528625,\n",
       "    0.01726922020316124,\n",
       "    0.01689600758254528,\n",
       "    0.007417438551783562,\n",
       "    0.013718532398343086,\n",
       "    0.0168863944709301,\n",
       "    0.013702407479286194,\n",
       "    0.011742697097361088,\n",
       "    0.016411902382969856,\n",
       "    0.015101674944162369,\n",
       "    0.008729496039450169,\n",
       "    0.008754921145737171,\n",
       "    0.01209065318107605,\n",
       "    0.015023505315184593,\n",
       "    0.015563874505460262,\n",
       "    0.016102874651551247,\n",
       "    0.015063593164086342,\n",
       "    0.016962984576821327,\n",
       "    0.009199935011565685,\n",
       "    0.01691836677491665,\n",
       "    0.01170540414750576,\n",
       "    0.008304251357913017,\n",
       "    0.01097504235804081,\n",
       "    0.01257274765521288,\n",
       "    0.013752096332609653,\n",
       "    0.013749955222010612,\n",
       "    0.01802169345319271,\n",
       "    0.012872516177594662,\n",
       "    0.01527722179889679,\n",
       "    0.012874976731836796,\n",
       "    0.010864578187465668,\n",
       "    0.010391796939074993,\n",
       "    0.012264853343367577,\n",
       "    0.0154708381742239,\n",
       "    0.012679489329457283,\n",
       "    0.017020544037222862,\n",
       "    0.011242994107306004,\n",
       "    0.013516551814973354,\n",
       "    0.013794628903269768,\n",
       "    0.01426844671368599,\n",
       "    0.01451912708580494,\n",
       "    0.012363163754343987,\n",
       "    0.01107534859329462,\n",
       "    0.011318724602460861,\n",
       "    0.012601463124155998,\n",
       "    0.010234510526061058,\n",
       "    0.019454052671790123,\n",
       "    0.01845690980553627,\n",
       "    0.01088254526257515,\n",
       "    0.015366247855126858,\n",
       "    0.01779191568493843,\n",
       "    0.016677720472216606,\n",
       "    0.013710808008909225,\n",
       "    0.00979907251894474,\n",
       "    0.009243739768862724,\n",
       "    0.009462937712669373,\n",
       "    0.013639000244438648,\n",
       "    0.013976949267089367,\n",
       "    0.013412220403552055,\n",
       "    0.01738821342587471,\n",
       "    0.009621902368962765,\n",
       "    0.015341714024543762,\n",
       "    0.01995440386235714,\n",
       "    0.016828501597046852,\n",
       "    0.01762995310127735,\n",
       "    0.017624014988541603,\n",
       "    0.014267133548855782,\n",
       "    0.01922663114964962,\n",
       "    0.015225090086460114,\n",
       "    0.012151429429650307,\n",
       "    0.019394157454371452,\n",
       "    0.013284892775118351,\n",
       "    0.011799642816185951,\n",
       "    0.014767630025744438,\n",
       "    0.01843537576496601,\n",
       "    0.01584724336862564,\n",
       "    0.01595660299062729,\n",
       "    0.012928628362715244,\n",
       "    0.01213679276406765,\n",
       "    0.017191508784890175,\n",
       "    0.014636300504207611,\n",
       "    0.013602611608803272,\n",
       "    0.01651032082736492,\n",
       "    0.014713437296450138,\n",
       "    0.008062385022640228,\n",
       "    0.012468608096241951,\n",
       "    0.013410292565822601,\n",
       "    0.01902352087199688,\n",
       "    0.009269398637115955,\n",
       "    0.00703564053401351,\n",
       "    0.020485052838921547,\n",
       "    0.011535082012414932,\n",
       "    0.015341576188802719,\n",
       "    0.0174415223300457,\n",
       "    0.009046466089785099,\n",
       "    0.017280451953411102,\n",
       "    0.016453156247735023,\n",
       "    0.015406191349029541,\n",
       "    0.007803570944815874,\n",
       "    0.013748647645115852,\n",
       "    0.017658233642578125,\n",
       "    0.010651995427906513,\n",
       "    0.01809259131550789,\n",
       "    0.013736508786678314,\n",
       "    0.010488332249224186,\n",
       "    0.011039204895496368,\n",
       "    0.010842682793736458,\n",
       "    0.011011573486030102,\n",
       "    0.013152005150914192,\n",
       "    0.009365839883685112,\n",
       "    0.010711273178458214,\n",
       "    0.013369223102927208,\n",
       "    0.013958040624856949,\n",
       "    0.01405926514416933,\n",
       "    0.014853160828351974,\n",
       "    0.011770924553275108,\n",
       "    0.0071990517899394035,\n",
       "    0.011050588451325893,\n",
       "    0.015215449966490269,\n",
       "    0.01953699067234993,\n",
       "    0.01226409338414669,\n",
       "    0.018017146736383438,\n",
       "    0.013921969570219517,\n",
       "    0.011600039899349213,\n",
       "    0.014292826876044273,\n",
       "    0.008885296992957592,\n",
       "    0.010514993220567703,\n",
       "    0.013431350700557232,\n",
       "    0.0076570166274905205,\n",
       "    0.014552447013556957,\n",
       "    0.010864394716918468,\n",
       "    0.009700555354356766,\n",
       "    0.015590458177030087,\n",
       "    0.012809689156711102,\n",
       "    0.012548095546662807,\n",
       "    0.01649552211165428,\n",
       "    0.019248243421316147,\n",
       "    0.01811336725950241,\n",
       "    0.012847171165049076,\n",
       "    0.014412961900234222,\n",
       "    0.01378512755036354,\n",
       "    0.015609744004905224,\n",
       "    0.020834732800722122,\n",
       "    0.01552936527878046,\n",
       "    0.009187592193484306,\n",
       "    0.010679075494408607,\n",
       "    0.011383667588233948,\n",
       "    0.013960392214357853,\n",
       "    0.01664664037525654,\n",
       "    0.01454201526939869,\n",
       "    0.013385399244725704,\n",
       "    0.016832495108246803,\n",
       "    0.014301405288279057,\n",
       "    0.014595834538340569,\n",
       "    0.01844257116317749,\n",
       "    0.017304765060544014,\n",
       "    0.012482789345085621,\n",
       "    0.00839950144290924,\n",
       "    0.012749266810715199,\n",
       "    0.015393792651593685,\n",
       "    0.011486481875181198,\n",
       "    0.015691153705120087,\n",
       "    0.01594717428088188,\n",
       "    0.013028711080551147,\n",
       "    0.013337342068552971]}),\n",
       " (LogisticRegression2H(\n",
       "    (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (ac1): Sigmoid()\n",
       "    (fc2): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (ac2): Sigmoid()\n",
       "    (fc3): Linear(in_features=784, out_features=10, bias=True)\n",
       "  ),\n",
       "  {'fc1.weight': [3.086906872340478e-05,\n",
       "    4.602958506438881e-05,\n",
       "    3.5696913982974365e-05,\n",
       "    3.529806781443767e-05,\n",
       "    3.403310620342381e-05,\n",
       "    3.645787728601135e-05,\n",
       "    3.700214801938273e-05,\n",
       "    3.6877063394058496e-05,\n",
       "    3.604040830396116e-05,\n",
       "    3.554427166818641e-05,\n",
       "    3.708734584506601e-05,\n",
       "    3.596398528316058e-05,\n",
       "    3.859277785522863e-05,\n",
       "    3.764469511224888e-05,\n",
       "    3.52574534190353e-05,\n",
       "    3.665411350084469e-05,\n",
       "    3.6751185689354315e-05,\n",
       "    3.5813998692901805e-05,\n",
       "    3.583366924431175e-05,\n",
       "    3.768088936340064e-05,\n",
       "    3.590620690374635e-05,\n",
       "    4.1443992813583463e-05,\n",
       "    3.373338404344395e-05,\n",
       "    3.700637535075657e-05,\n",
       "    3.891091182595119e-05,\n",
       "    3.474584445939399e-05,\n",
       "    4.096501288586296e-05,\n",
       "    3.2624764571664855e-05,\n",
       "    3.500961611280218e-05,\n",
       "    3.392778671695851e-05,\n",
       "    3.504766573314555e-05,\n",
       "    3.540033503668383e-05,\n",
       "    3.5566845326684415e-05,\n",
       "    4.0697505028219894e-05,\n",
       "    3.3876702218549326e-05,\n",
       "    3.82513644581195e-05,\n",
       "    3.646565164672211e-05,\n",
       "    3.8286103517748415e-05,\n",
       "    3.6445951991481707e-05,\n",
       "    3.175975871272385e-05,\n",
       "    3.639825445134193e-05,\n",
       "    4.1247374610975385e-05,\n",
       "    4.000604531029239e-05,\n",
       "    3.382377326488495e-05,\n",
       "    3.71913738490548e-05,\n",
       "    3.615599780459888e-05,\n",
       "    3.269634544267319e-05,\n",
       "    4.000500121037476e-05,\n",
       "    3.581613418646157e-05,\n",
       "    3.697631473187357e-05,\n",
       "    3.5651995858643204e-05,\n",
       "    3.418337655602954e-05,\n",
       "    3.9872171328170225e-05,\n",
       "    3.792540155700408e-05,\n",
       "    3.4152439184254035e-05,\n",
       "    3.485288470983505e-05,\n",
       "    3.976686275564134e-05,\n",
       "    3.597879913286306e-05,\n",
       "    3.595444650272839e-05,\n",
       "    3.230862785130739e-05,\n",
       "    3.880871372530237e-05,\n",
       "    3.520038444548845e-05,\n",
       "    3.457293860265054e-05,\n",
       "    3.4521694033173844e-05,\n",
       "    3.4067401429638267e-05,\n",
       "    3.611678403103724e-05,\n",
       "    3.9605518395546824e-05,\n",
       "    3.535268479026854e-05,\n",
       "    3.234391624573618e-05,\n",
       "    3.627647674875334e-05,\n",
       "    3.521899998304434e-05,\n",
       "    3.430608194321394e-05,\n",
       "    3.3796321076806635e-05,\n",
       "    3.7024270568508655e-05,\n",
       "    3.4698659874266014e-05,\n",
       "    4.160422759014182e-05,\n",
       "    3.304334313725121e-05,\n",
       "    4.117380012758076e-05,\n",
       "    3.708683652803302e-05,\n",
       "    3.376089080120437e-05,\n",
       "    3.7670484744012356e-05,\n",
       "    3.986667434219271e-05,\n",
       "    4.053211523569189e-05,\n",
       "    4.176269067102112e-05,\n",
       "    3.7740723200840876e-05,\n",
       "    3.386811295058578e-05,\n",
       "    3.545586150721647e-05,\n",
       "    3.82664475182537e-05,\n",
       "    3.732684126589447e-05,\n",
       "    3.634508539107628e-05,\n",
       "    3.3150616218335927e-05,\n",
       "    3.303430275991559e-05,\n",
       "    4.112942042411305e-05,\n",
       "    3.626690522651188e-05,\n",
       "    3.4263233828824013e-05,\n",
       "    3.7319481634767726e-05,\n",
       "    3.798536999966018e-05,\n",
       "    3.692505924846046e-05,\n",
       "    3.672415186883882e-05,\n",
       "    3.862062658299692e-05,\n",
       "    3.791477138292976e-05,\n",
       "    3.8214966480154544e-05,\n",
       "    3.713807018357329e-05,\n",
       "    3.504365304252133e-05,\n",
       "    3.8374979340005666e-05,\n",
       "    3.9259841287275776e-05,\n",
       "    3.8195001252461225e-05,\n",
       "    3.5483059036778286e-05,\n",
       "    3.975666913902387e-05,\n",
       "    3.52233910234645e-05,\n",
       "    3.74520750483498e-05,\n",
       "    3.8927839341340587e-05,\n",
       "    4.179589086561464e-05,\n",
       "    3.7373298255261034e-05,\n",
       "    4.1545576095813885e-05,\n",
       "    3.097422086284496e-05,\n",
       "    3.395944077055901e-05,\n",
       "    3.210777140338905e-05,\n",
       "    4.0034552512224764e-05,\n",
       "    3.6471159546636045e-05,\n",
       "    4.1619230614742264e-05,\n",
       "    3.294191265013069e-05,\n",
       "    3.428026320762001e-05,\n",
       "    3.225560794817284e-05,\n",
       "    3.840616045636125e-05,\n",
       "    3.9292677683988586e-05,\n",
       "    3.816294702119194e-05,\n",
       "    3.730977914528921e-05,\n",
       "    3.190429924870841e-05,\n",
       "    3.8045716792112216e-05,\n",
       "    3.536108124535531e-05,\n",
       "    3.391753853065893e-05,\n",
       "    3.4246855648234487e-05,\n",
       "    3.1096049497136846e-05,\n",
       "    3.8839141780044883e-05,\n",
       "    3.436030965531245e-05,\n",
       "    3.8975813367869705e-05,\n",
       "    3.097794979112223e-05,\n",
       "    3.3531592634972185e-05,\n",
       "    3.3463304134784266e-05,\n",
       "    3.3254855225095525e-05,\n",
       "    3.459811341599561e-05,\n",
       "    3.536613075993955e-05,\n",
       "    3.622944495873526e-05,\n",
       "    3.931856554117985e-05,\n",
       "    3.3722280932124704e-05,\n",
       "    3.497944999253377e-05,\n",
       "    3.5415607271716e-05,\n",
       "    3.6210447433404624e-05,\n",
       "    3.8111964386189356e-05,\n",
       "    3.4916789445560426e-05,\n",
       "    3.856214607367292e-05,\n",
       "    3.2117488444782794e-05,\n",
       "    3.9584851037943736e-05,\n",
       "    3.954203930334188e-05,\n",
       "    3.819408084382303e-05,\n",
       "    3.5903587559005246e-05,\n",
       "    3.887907587341033e-05,\n",
       "    4.459642877918668e-05,\n",
       "    4.018122490379028e-05,\n",
       "    4.288574928068556e-05,\n",
       "    3.394408486201428e-05,\n",
       "    3.577753886929713e-05,\n",
       "    3.091373946517706e-05,\n",
       "    3.2887117413338274e-05,\n",
       "    3.668381032184698e-05,\n",
       "    4.242363138473593e-05,\n",
       "    3.742698027053848e-05,\n",
       "    3.5664477763930336e-05,\n",
       "    3.773357093450613e-05,\n",
       "    3.319698225823231e-05,\n",
       "    3.3656044251983985e-05,\n",
       "    3.515683420118876e-05,\n",
       "    3.769025352085009e-05,\n",
       "    3.793570795096457e-05,\n",
       "    3.1656803912483156e-05,\n",
       "    3.5072338505415246e-05,\n",
       "    3.695236591738649e-05,\n",
       "    4.14431378885638e-05,\n",
       "    3.5494816984282807e-05,\n",
       "    3.9556394767714664e-05,\n",
       "    3.576114249881357e-05,\n",
       "    3.616550748120062e-05,\n",
       "    3.919636219507083e-05,\n",
       "    3.4303437132621184e-05,\n",
       "    3.6677622119896114e-05,\n",
       "    3.343004937050864e-05,\n",
       "    3.503374682622962e-05,\n",
       "    3.843479498755187e-05,\n",
       "    3.376441236468963e-05,\n",
       "    3.325526631670073e-05,\n",
       "    3.6714624002343044e-05,\n",
       "    3.6505247408058494e-05,\n",
       "    3.728561569005251e-05,\n",
       "    3.6098728742217645e-05,\n",
       "    4.11032306146808e-05,\n",
       "    4.0999733755597845e-05,\n",
       "    3.6966273910366e-05,\n",
       "    3.690419180202298e-05,\n",
       "    3.625787576311268e-05,\n",
       "    3.806232416536659e-05,\n",
       "    3.695041232276708e-05,\n",
       "    2.8820471925428137e-05,\n",
       "    3.750843461602926e-05,\n",
       "    3.541993646649644e-05,\n",
       "    3.280783857917413e-05,\n",
       "    3.882119926856831e-05,\n",
       "    4.23054261773359e-05,\n",
       "    3.296631621196866e-05,\n",
       "    3.668099088827148e-05,\n",
       "    3.864523023366928e-05,\n",
       "    3.0364966733031906e-05,\n",
       "    3.554332215571776e-05,\n",
       "    4.122199607081711e-05,\n",
       "    3.874146204907447e-05,\n",
       "    3.362221104907803e-05,\n",
       "    3.596776150516234e-05,\n",
       "    3.647993071353994e-05,\n",
       "    3.4613360185176134e-05,\n",
       "    3.601582648116164e-05,\n",
       "    3.441387525526807e-05,\n",
       "    4.02335099352058e-05,\n",
       "    3.229490903322585e-05,\n",
       "    3.4421671443851665e-05,\n",
       "    4.138469012104906e-05,\n",
       "    3.763349377550185e-05,\n",
       "    3.517890945659019e-05,\n",
       "    3.1540344934910536e-05,\n",
       "    3.500459570204839e-05,\n",
       "    3.3681237255223095e-05,\n",
       "    3.3816548238974065e-05,\n",
       "    3.70483539882116e-05,\n",
       "    3.212014780729078e-05,\n",
       "    3.432852463447489e-05,\n",
       "    3.8604885048698634e-05,\n",
       "    3.4617700293892995e-05,\n",
       "    3.485038541839458e-05,\n",
       "    3.802183346124366e-05,\n",
       "    4.19275565946009e-05,\n",
       "    3.708229269250296e-05,\n",
       "    3.885419209836982e-05,\n",
       "    3.522799670463428e-05,\n",
       "    3.45093067153357e-05,\n",
       "    4.161526885582134e-05,\n",
       "    3.924616612493992e-05,\n",
       "    3.931343599106185e-05,\n",
       "    3.839532291749492e-05,\n",
       "    3.5663426388055086e-05,\n",
       "    3.9286274841288105e-05,\n",
       "    3.4660155506571755e-05,\n",
       "    3.6453759094001725e-05,\n",
       "    4.1349674575030804e-05,\n",
       "    3.990880577475764e-05,\n",
       "    3.2616218959446996e-05,\n",
       "    3.2002342777559534e-05,\n",
       "    3.5429820854915306e-05,\n",
       "    3.353182182763703e-05,\n",
       "    3.677716449601576e-05,\n",
       "    4.100552177987993e-05,\n",
       "    3.5114921047352254e-05,\n",
       "    3.0623421480413526e-05,\n",
       "    3.597534669097513e-05,\n",
       "    3.6496701795840636e-05,\n",
       "    3.915739944204688e-05,\n",
       "    3.555557123036124e-05,\n",
       "    3.4787535696523264e-05,\n",
       "    3.630961145972833e-05,\n",
       "    3.1983265216695145e-05,\n",
       "    3.72828399122227e-05,\n",
       "    3.583838406484574e-05,\n",
       "    3.6028053727932274e-05,\n",
       "    4.261976573616266e-05,\n",
       "    3.313118213554844e-05,\n",
       "    3.608028418966569e-05,\n",
       "    3.5919863876188174e-05,\n",
       "    3.888447463396005e-05,\n",
       "    3.895998088410124e-05,\n",
       "    4.386463842820376e-05,\n",
       "    3.3794556657085195e-05,\n",
       "    3.942542025470175e-05,\n",
       "    3.3480006095487624e-05,\n",
       "    3.796004966716282e-05,\n",
       "    3.958905290346593e-05,\n",
       "    3.576503513613716e-05,\n",
       "    3.4302483982173726e-05,\n",
       "    3.465618647169322e-05,\n",
       "    3.866406041197479e-05,\n",
       "    3.8833961298223585e-05,\n",
       "    3.605319943744689e-05,\n",
       "    3.890829611918889e-05,\n",
       "    3.364826625329442e-05,\n",
       "    3.4796979889506474e-05,\n",
       "    3.853606540360488e-05,\n",
       "    3.384648880455643e-05,\n",
       "    3.639501301222481e-05,\n",
       "    3.9118702261475846e-05,\n",
       "    3.484567059786059e-05,\n",
       "    3.526138243614696e-05,\n",
       "    3.1830928492126986e-05,\n",
       "    3.231229857192375e-05,\n",
       "    3.70179332094267e-05,\n",
       "    3.7391633668448776e-05,\n",
       "    3.533562266966328e-05,\n",
       "    3.464620021986775e-05,\n",
       "    3.646404729806818e-05,\n",
       "    3.817383185378276e-05,\n",
       "    3.6462253774516284e-05,\n",
       "    3.72061476809904e-05,\n",
       "    3.478859071037732e-05,\n",
       "    3.613726221374236e-05,\n",
       "    3.3501106372568756e-05,\n",
       "    3.4004944609478116e-05,\n",
       "    3.5949258744949475e-05,\n",
       "    3.813160219579004e-05,\n",
       "    3.6365665437188e-05,\n",
       "    3.633123924373649e-05,\n",
       "    3.8944279367569834e-05,\n",
       "    3.792944335145876e-05,\n",
       "    3.6841312976321205e-05,\n",
       "    3.378427209099755e-05,\n",
       "    3.447656854405068e-05,\n",
       "    3.806110908044502e-05,\n",
       "    3.657091656350531e-05,\n",
       "    4.043418448418379e-05,\n",
       "    3.729285890585743e-05,\n",
       "    3.3285152312600985e-05,\n",
       "    3.350895713083446e-05,\n",
       "    3.453525641816668e-05,\n",
       "    3.797266981564462e-05,\n",
       "    4.1613249777583405e-05,\n",
       "    3.508145164232701e-05,\n",
       "    3.4453667467460036e-05,\n",
       "    3.8550744648091495e-05,\n",
       "    4.0485527279088274e-05,\n",
       "    3.6090823414269835e-05,\n",
       "    4.3570009438553825e-05,\n",
       "    3.7568173866020516e-05,\n",
       "    3.551890767994337e-05,\n",
       "    3.674492472782731e-05,\n",
       "    3.478980579529889e-05,\n",
       "    3.919279697583988e-05,\n",
       "    3.566351006156765e-05,\n",
       "    3.94002090615686e-05,\n",
       "    4.306410482968204e-05,\n",
       "    3.934041887987405e-05,\n",
       "    3.185660898452625e-05,\n",
       "    3.7905418139416724e-05,\n",
       "    3.5771179682342336e-05,\n",
       "    3.2078271033242345e-05,\n",
       "    4.156185605097562e-05,\n",
       "    3.565167571650818e-05,\n",
       "    4.108386201551184e-05,\n",
       "    3.2077208743430674e-05,\n",
       "    3.7548459658864886e-05,\n",
       "    3.366492092027329e-05,\n",
       "    3.496205317787826e-05,\n",
       "    3.4925509680761024e-05,\n",
       "    3.414469028939493e-05,\n",
       "    4.22050325141754e-05,\n",
       "    4.463802179088816e-05,\n",
       "    3.471671880106442e-05,\n",
       "    4.123571125091985e-05,\n",
       "    4.1252664232160896e-05,\n",
       "    3.553813075996004e-05,\n",
       "    3.670947626233101e-05],\n",
       "   'fc2.weight': [0.00011213219113415107,\n",
       "    0.00027824388234876096,\n",
       "    0.0001366400538245216,\n",
       "    0.0001506754051661119,\n",
       "    0.0001269576750928536,\n",
       "    0.00013550026051234454,\n",
       "    0.00013205743744038045,\n",
       "    0.00016044812218751758,\n",
       "    0.00017318723257631063,\n",
       "    0.000206229931791313,\n",
       "    0.0001636273809708655,\n",
       "    0.00016992079326882958,\n",
       "    0.00030461495043709874,\n",
       "    0.00019216373038943857,\n",
       "    0.00017765657685231417,\n",
       "    0.0002218532608821988,\n",
       "    0.00019727862672880292,\n",
       "    0.0001629391626920551,\n",
       "    0.00019811367383226752,\n",
       "    0.00018014878151006997,\n",
       "    0.00018624428776092827,\n",
       "    0.0002278086612932384,\n",
       "    0.00016828643856570125,\n",
       "    0.00019510880520101637,\n",
       "    0.00025425193598493934,\n",
       "    0.00018921900482382625,\n",
       "    0.00018318957882001996,\n",
       "    0.00015419238479807973,\n",
       "    0.00021305221889633685,\n",
       "    0.00024664337979629636,\n",
       "    0.00016614608466625214,\n",
       "    0.00020009945728816092,\n",
       "    0.00016141639207489789,\n",
       "    0.0002365723776165396,\n",
       "    0.0001309398649027571,\n",
       "    0.00020128130563534796,\n",
       "    0.0001870781125035137,\n",
       "    0.00018993615231011063,\n",
       "    0.00017982239660341293,\n",
       "    0.00011901711695827544,\n",
       "    0.0002826589916367084,\n",
       "    0.00030723330564796925,\n",
       "    0.00024837421369738877,\n",
       "    0.00013334493269212544,\n",
       "    0.00018885206372942775,\n",
       "    0.00016672132187522948,\n",
       "    0.0002099711709888652,\n",
       "    0.00025716819800436497,\n",
       "    0.00020533618226181716,\n",
       "    0.00017212390957865864,\n",
       "    0.0001537921343697235,\n",
       "    0.0002182822354370728,\n",
       "    0.0001650241611059755,\n",
       "    0.0002489048056304455,\n",
       "    0.00011014887422788888,\n",
       "    0.00020399758068379015,\n",
       "    0.00028150761500000954,\n",
       "    0.00020917081565130502,\n",
       "    0.00017736184236127883,\n",
       "    0.00012138673628214747,\n",
       "    0.00016162125393748283,\n",
       "    0.00016512985166627914,\n",
       "    0.00017065525753423572,\n",
       "    0.00021277552878018469,\n",
       "    0.00016343315655831248,\n",
       "    0.00022338646522257477,\n",
       "    0.0002777816553134471,\n",
       "    0.00018582136544864625,\n",
       "    0.00014972260396461934,\n",
       "    0.00021457302500493824,\n",
       "    0.00015585366054438055,\n",
       "    0.00015874762902967632,\n",
       "    0.00013834363198839128,\n",
       "    0.0001647610479267314,\n",
       "    0.0001798382872948423,\n",
       "    0.00029193685622885823,\n",
       "    0.00015252531738951802,\n",
       "    0.00022852455731481314,\n",
       "    0.0002556003164499998,\n",
       "    0.00015576141595374793,\n",
       "    0.0001612095074960962,\n",
       "    0.00030233256984502077,\n",
       "    0.00020253888214938343,\n",
       "    0.00024050960200838745,\n",
       "    0.0001774304109858349,\n",
       "    0.00014051269681658596,\n",
       "    0.0001461617212044075,\n",
       "    0.00023076643992681056,\n",
       "    0.00028558087069541216,\n",
       "    0.0001807850057957694,\n",
       "    0.00013910268899053335,\n",
       "    0.000195167405763641,\n",
       "    0.0002056687808362767,\n",
       "    0.00017806439427658916,\n",
       "    0.0001248747284989804,\n",
       "    0.00019342340237926692,\n",
       "    0.00023189639614429325,\n",
       "    0.00013917757314629853,\n",
       "    0.00019360265287104994,\n",
       "    0.00018132234981749207,\n",
       "    0.00015646089741494507,\n",
       "    0.0002327514230273664,\n",
       "    0.0002289361582370475,\n",
       "    0.000155746573000215,\n",
       "    0.0002093389630317688,\n",
       "    0.00024560943711549044,\n",
       "    0.0002037155209109187,\n",
       "    0.00021495611872524023,\n",
       "    0.00025398441357538104,\n",
       "    0.00017388783453498036,\n",
       "    0.00021036455291323364,\n",
       "    0.00023196246183943003,\n",
       "    0.00024620202020742,\n",
       "    0.0002392327442066744,\n",
       "    0.0002602938038762659,\n",
       "    8.672618423588574e-05,\n",
       "    0.00015831959899514914,\n",
       "    0.00013101600052323192,\n",
       "    0.00021953003306407481,\n",
       "    0.00019612046889960766,\n",
       "    0.00027400627732276917,\n",
       "    0.00016670238983351737,\n",
       "    0.00014025112614035606,\n",
       "    0.00020708372176159173,\n",
       "    0.0002540710265748203,\n",
       "    0.00020149804186075926,\n",
       "    0.0001982593530556187,\n",
       "    0.00022389242076314986,\n",
       "    0.00013558004866354167,\n",
       "    0.00019179799710400403,\n",
       "    0.00017660370212979615,\n",
       "    0.00015286196139641106,\n",
       "    0.00013979054347146302,\n",
       "    0.00012043378228554502,\n",
       "    0.0002318090118933469,\n",
       "    0.00016627809964120388,\n",
       "    0.00022122445807326585,\n",
       "    0.00019667721062432975,\n",
       "    0.00016219586541410536,\n",
       "    0.00017205534095410258,\n",
       "    0.00015791812620591372,\n",
       "    0.00018112965335603803,\n",
       "    0.0001941191148944199,\n",
       "    0.00013683814904652536,\n",
       "    0.00023565816809423268,\n",
       "    0.00017187533376272768,\n",
       "    0.00022093282314017415,\n",
       "    0.00022538074699696153,\n",
       "    0.00019374133262317628,\n",
       "    0.00025009678211063147,\n",
       "    0.00012771098408848047,\n",
       "    0.00016320779104717076,\n",
       "    0.00016765465261414647,\n",
       "    0.00021966481290291995,\n",
       "    0.00022535950120072812,\n",
       "    0.00018588121747598052,\n",
       "    0.00020845745166298002,\n",
       "    0.00019211317703593522,\n",
       "    0.00028581611695699394,\n",
       "    0.0002655468706507236,\n",
       "    0.0002795990149024874,\n",
       "    0.0001972271129488945,\n",
       "    0.00023051112657412887,\n",
       "    0.00021106672647874802,\n",
       "    0.00016309863713104278,\n",
       "    0.00018124897906091064,\n",
       "    0.0002826185373123735,\n",
       "    0.00019821114256046712,\n",
       "    0.0001611180487088859,\n",
       "    0.0001736908743623644,\n",
       "    0.00010666088928701356,\n",
       "    0.00014469058078248054,\n",
       "    0.00012339542445261031,\n",
       "    0.00014968671894166619,\n",
       "    0.00022068269026931375,\n",
       "    0.0001314669061684981,\n",
       "    0.0002055659278994426,\n",
       "    0.00022725896269548684,\n",
       "    0.00027996455901302397,\n",
       "    0.00024318751820828766,\n",
       "    0.0002370236616116017,\n",
       "    0.0001404803042532876,\n",
       "    0.00021669997659046203,\n",
       "    0.0002419922238914296,\n",
       "    0.00015536307182628661,\n",
       "    0.00017313726129941642,\n",
       "    0.00021686659601982683,\n",
       "    0.0001733910758048296,\n",
       "    0.00022944866213947535,\n",
       "    0.00016827422950882465,\n",
       "    0.00010975058103213087,\n",
       "    0.00016647216398268938,\n",
       "    0.00015782461559865624,\n",
       "    0.0001743859174894169,\n",
       "    0.00023833407612983137,\n",
       "    0.0002620017621666193,\n",
       "    0.0002728923282120377,\n",
       "    0.00015949297812767327,\n",
       "    0.00023926836729515344,\n",
       "    0.0001594575442140922,\n",
       "    0.00028539547929540277,\n",
       "    0.00018526689382269979,\n",
       "    9.841799328569323e-05,\n",
       "    0.0002124288002960384,\n",
       "    0.0001513232127763331,\n",
       "    0.00016008350939955562,\n",
       "    0.00026909945881925523,\n",
       "    0.0002255116996821016,\n",
       "    0.00024387308803852648,\n",
       "    0.00019222375703975558,\n",
       "    0.0002002418477786705,\n",
       "    0.0001963550748769194,\n",
       "    0.0001768508809618652,\n",
       "    0.00029330814140848815,\n",
       "    0.0001778868754627183,\n",
       "    0.00013867346569895744,\n",
       "    0.000214104846236296,\n",
       "    0.00015755172353237867,\n",
       "    0.0001378887245664373,\n",
       "    0.00026506706490181386,\n",
       "    0.0002372952294535935,\n",
       "    0.00021522067254409194,\n",
       "    0.000156207854161039,\n",
       "    0.00017436828056816012,\n",
       "    0.0002695934381335974,\n",
       "    0.0002123059384757653,\n",
       "    0.0001935090695042163,\n",
       "    0.00014021704555489123,\n",
       "    0.00012476601114030927,\n",
       "    0.00018620687478687614,\n",
       "    0.00012756852083839476,\n",
       "    0.00016164712724275887,\n",
       "    0.000182079485966824,\n",
       "    0.00011159826681250706,\n",
       "    0.00017160452262032777,\n",
       "    0.00012427715410012752,\n",
       "    0.0001838511525420472,\n",
       "    0.00020743727509398013,\n",
       "    0.00021174963330850005,\n",
       "    0.0002246995863970369,\n",
       "    0.00023474718909710646,\n",
       "    0.00020279153250157833,\n",
       "    0.00017227315402124077,\n",
       "    0.0002298721083207056,\n",
       "    0.000223141789319925,\n",
       "    0.00018489238573238254,\n",
       "    0.00025329069467261434,\n",
       "    0.00018151466792915016,\n",
       "    0.0002588793868198991,\n",
       "    0.0001827268279157579,\n",
       "    0.00014760202611796558,\n",
       "    0.0002555031096562743,\n",
       "    0.00028473004931584,\n",
       "    0.00019785227777902037,\n",
       "    0.00021734758047387004,\n",
       "    0.0001269327913178131,\n",
       "    0.00014037216897122562,\n",
       "    0.00018989262753166258,\n",
       "    0.0002140575525118038,\n",
       "    0.00017630161892157048,\n",
       "    0.00012382876593619585,\n",
       "    0.00017202748858835548,\n",
       "    0.00019427725055720657,\n",
       "    0.00022485977387987077,\n",
       "    0.000153244924149476,\n",
       "    0.0001942837261594832,\n",
       "    0.0001939092471729964,\n",
       "    0.00018268539861310273,\n",
       "    0.00020180844876449555,\n",
       "    0.00018898364214692265,\n",
       "    0.00020846800180152059,\n",
       "    0.0002487481979187578,\n",
       "    0.00011703771451720968,\n",
       "    0.0001745787012623623,\n",
       "    0.00019308879564050585,\n",
       "    0.00019642591360025108,\n",
       "    0.00031008562655188143,\n",
       "    0.00027757452335208654,\n",
       "    0.00014888792065903544,\n",
       "    0.00021598429884761572,\n",
       "    0.00016373679682146758,\n",
       "    0.0001320288865827024,\n",
       "    0.0002534272207412869,\n",
       "    0.0002076465025311336,\n",
       "    0.00013658375246450305,\n",
       "    0.0001750868104863912,\n",
       "    0.0002061000413959846,\n",
       "    0.00024446152383461595,\n",
       "    0.00014758858014829457,\n",
       "    0.00020346316159702837,\n",
       "    0.00014349544653669,\n",
       "    0.00016413764387834817,\n",
       "    0.00017740068142302334,\n",
       "    0.000213967461604625,\n",
       "    0.00021219161862973124,\n",
       "    0.00021587627998087555,\n",
       "    0.0001707624178379774,\n",
       "    0.00016592130123171955,\n",
       "    0.00015488461940549314,\n",
       "    0.0001818204327719286,\n",
       "    0.0001206155720865354,\n",
       "    0.00019229504687245935,\n",
       "    0.00016161828534677625,\n",
       "    0.00019074283773079515,\n",
       "    0.00017946567095350474,\n",
       "    0.00020931544713675976,\n",
       "    0.00018462541629560292,\n",
       "    0.00019449602405074984,\n",
       "    0.00016040245827753097,\n",
       "    0.0001771501119947061,\n",
       "    0.00013807497452944517,\n",
       "    0.00016912040882743895,\n",
       "    0.00020621734438464046,\n",
       "    0.0002275418082717806,\n",
       "    0.000270055141299963,\n",
       "    0.0001611468760529533,\n",
       "    0.00020582458819262683,\n",
       "    0.00010859658505069092,\n",
       "    0.0002622967294882983,\n",
       "    0.00014795623428653926,\n",
       "    0.00017733240383677185,\n",
       "    0.00021176711015868932,\n",
       "    0.00019686110317707062,\n",
       "    0.0002482706040609628,\n",
       "    0.00020272510300856084,\n",
       "    0.00015745870769023895,\n",
       "    0.00012265877739991993,\n",
       "    0.00020830902212765068,\n",
       "    0.0001901461073430255,\n",
       "    0.00024919287534430623,\n",
       "    0.00014514659414999187,\n",
       "    0.0001671078643994406,\n",
       "    0.0002129768836311996,\n",
       "    0.00022178012295626104,\n",
       "    0.00020826372201554477,\n",
       "    0.0002720975026022643,\n",
       "    0.00018334653577767313,\n",
       "    0.00013902437058277428,\n",
       "    0.00016705911548342556,\n",
       "    0.00013332851813174784,\n",
       "    0.00022532345610670745,\n",
       "    0.00019842525944113731,\n",
       "    0.00023214390967041254,\n",
       "    0.00023132660135161132,\n",
       "    0.0002028430171776563,\n",
       "    0.00013718401896767318,\n",
       "    0.0001751821837387979,\n",
       "    0.00016835538554005325,\n",
       "    0.00013360954471863806,\n",
       "    0.00024887852487154305,\n",
       "    0.00018339412054046988,\n",
       "    0.00021586540970019996,\n",
       "    0.00017543204012326896,\n",
       "    0.0001936510088853538,\n",
       "    0.00019490525301080197,\n",
       "    0.00014770939014852047,\n",
       "    0.00016471084381919354,\n",
       "    0.00017491620383225381,\n",
       "    0.00023085794236976653,\n",
       "    0.00029895134503021836,\n",
       "    0.00016842623881530017,\n",
       "    0.00024716704501770437,\n",
       "    0.00022804734180681407,\n",
       "    0.00016855463036336005,\n",
       "    0.0002076698438031599],\n",
       "   'fc3.weight': [0.006694807205349207,\n",
       "    0.016466254368424416,\n",
       "    0.009182249195873737,\n",
       "    0.009797790087759495,\n",
       "    0.007683913689106703,\n",
       "    0.008702756837010384,\n",
       "    0.007690279744565487,\n",
       "    0.009571188129484653,\n",
       "    0.011013643816113472,\n",
       "    0.009926855564117432,\n",
       "    0.00946072954684496,\n",
       "    0.01036673691123724,\n",
       "    0.019069641828536987,\n",
       "    0.013482729904353619,\n",
       "    0.012475911527872086,\n",
       "    0.012836732901632786,\n",
       "    0.013786539435386658,\n",
       "    0.010563301853835583,\n",
       "    0.011168465949594975,\n",
       "    0.012698089703917503,\n",
       "    0.012892012484371662,\n",
       "    0.013045811094343662,\n",
       "    0.00942927785217762,\n",
       "    0.011934801004827023,\n",
       "    0.015917465090751648,\n",
       "    0.012491531670093536,\n",
       "    0.01138175930827856,\n",
       "    0.009057036601006985,\n",
       "    0.015217923559248447,\n",
       "    0.017496397718787193,\n",
       "    0.008924831636250019,\n",
       "    0.01356445625424385,\n",
       "    0.008962417021393776,\n",
       "    0.015492093749344349,\n",
       "    0.006869642995297909,\n",
       "    0.012710978277027607,\n",
       "    0.012065754272043705,\n",
       "    0.011992438696324825,\n",
       "    0.010702734813094139,\n",
       "    0.007960187271237373,\n",
       "    0.01945406198501587,\n",
       "    0.01982720196247101,\n",
       "    0.013488668948411942,\n",
       "    0.007417355198413134,\n",
       "    0.012272592633962631,\n",
       "    0.010384747758507729,\n",
       "    0.01453475933521986,\n",
       "    0.016417205333709717,\n",
       "    0.013465231284499168,\n",
       "    0.010106522589921951,\n",
       "    0.009705404751002789,\n",
       "    0.011360738426446915,\n",
       "    0.010228410363197327,\n",
       "    0.015018178150057793,\n",
       "    0.007473448757082224,\n",
       "    0.012033951468765736,\n",
       "    0.016964638605713844,\n",
       "    0.015355957671999931,\n",
       "    0.011881154030561447,\n",
       "    0.0076188938692212105,\n",
       "    0.011072962544858456,\n",
       "    0.009428330697119236,\n",
       "    0.010387532413005829,\n",
       "    0.012928075157105923,\n",
       "    0.011133947409689426,\n",
       "    0.014620289206504822,\n",
       "    0.0193477813154459,\n",
       "    0.00983921904116869,\n",
       "    0.009475934319198132,\n",
       "    0.010807310231029987,\n",
       "    0.009371395222842693,\n",
       "    0.009570280089974403,\n",
       "    0.009324838407337666,\n",
       "    0.011633976362645626,\n",
       "    0.012527518905699253,\n",
       "    0.019680077210068703,\n",
       "    0.0077811176888644695,\n",
       "    0.01467859372496605,\n",
       "    0.017385264858603477,\n",
       "    0.009940939955413342,\n",
       "    0.009091709740459919,\n",
       "    0.017228752374649048,\n",
       "    0.013110630214214325,\n",
       "    0.016580870375037193,\n",
       "    0.010520847514271736,\n",
       "    0.007460101507604122,\n",
       "    0.00943042803555727,\n",
       "    0.012774497270584106,\n",
       "    0.01571490988135338,\n",
       "    0.01158326305449009,\n",
       "    0.008431677706539631,\n",
       "    0.013262182474136353,\n",
       "    0.013701300136744976,\n",
       "    0.010661023668944836,\n",
       "    0.0086669335141778,\n",
       "    0.012587526813149452,\n",
       "    0.014068108052015305,\n",
       "    0.008634320460259914,\n",
       "    0.012514762580394745,\n",
       "    0.009979462251067162,\n",
       "    0.009862332604825497,\n",
       "    0.015654072165489197,\n",
       "    0.013985635712742805,\n",
       "    0.009170318022370338,\n",
       "    0.013421565294265747,\n",
       "    0.01558973640203476,\n",
       "    0.014628556556999683,\n",
       "    0.01195004116743803,\n",
       "    0.014981572516262531,\n",
       "    0.009823298081755638,\n",
       "    0.014619938097894192,\n",
       "    0.013666961342096329,\n",
       "    0.014634286053478718,\n",
       "    0.013590872287750244,\n",
       "    0.01698186807334423,\n",
       "    0.005207596812397242,\n",
       "    0.008312725462019444,\n",
       "    0.007005565799772739,\n",
       "    0.012258139438927174,\n",
       "    0.013104666955769062,\n",
       "    0.017535638064146042,\n",
       "    0.010542611591517925,\n",
       "    0.009362416341900826,\n",
       "    0.01425386406481266,\n",
       "    0.01416256744414568,\n",
       "    0.012300028465688229,\n",
       "    0.013271606527268887,\n",
       "    0.01665090024471283,\n",
       "    0.007275477983057499,\n",
       "    0.009867285378277302,\n",
       "    0.011105463840067387,\n",
       "    0.00901513360440731,\n",
       "    0.0084585752338171,\n",
       "    0.007807649672031403,\n",
       "    0.01531030610203743,\n",
       "    0.010099349543452263,\n",
       "    0.012630562297999859,\n",
       "    0.012332373298704624,\n",
       "    0.009574279189109802,\n",
       "    0.010736271739006042,\n",
       "    0.009314538910984993,\n",
       "    0.01062960084527731,\n",
       "    0.012846190482378006,\n",
       "    0.008393697440624237,\n",
       "    0.015205769799649715,\n",
       "    0.012055539526045322,\n",
       "    0.012347298674285412,\n",
       "    0.013844680972397327,\n",
       "    0.010876425541937351,\n",
       "    0.015952778980135918,\n",
       "    0.008402657695114613,\n",
       "    0.009091650135815144,\n",
       "    0.01237344928085804,\n",
       "    0.014810849912464619,\n",
       "    0.014091669581830502,\n",
       "    0.011612196452915668,\n",
       "    0.013546963222324848,\n",
       "    0.012231536209583282,\n",
       "    0.017941726371645927,\n",
       "    0.01655488647520542,\n",
       "    0.017788881435990334,\n",
       "    0.0127315204590559,\n",
       "    0.01418981608003378,\n",
       "    0.013007412664592266,\n",
       "    0.010146685875952244,\n",
       "    0.011121466755867004,\n",
       "    0.014091969467699528,\n",
       "    0.013652085326611996,\n",
       "    0.010083122178912163,\n",
       "    0.011432139202952385,\n",
       "    0.006281151901930571,\n",
       "    0.00820988230407238,\n",
       "    0.007915118709206581,\n",
       "    0.0085721081122756,\n",
       "    0.01143640372902155,\n",
       "    0.00799180381000042,\n",
       "    0.01264907605946064,\n",
       "    0.013201870955526829,\n",
       "    0.018397999927401543,\n",
       "    0.013438006862998009,\n",
       "    0.015061900019645691,\n",
       "    0.008663958869874477,\n",
       "    0.013177506625652313,\n",
       "    0.016509225592017174,\n",
       "    0.009264950640499592,\n",
       "    0.010550538077950478,\n",
       "    0.014391510747373104,\n",
       "    0.01062154769897461,\n",
       "    0.012590605765581131,\n",
       "    0.010803619399666786,\n",
       "    0.006687989458441734,\n",
       "    0.010957668535411358,\n",
       "    0.010151120834052563,\n",
       "    0.011349393054842949,\n",
       "    0.01636439375579357,\n",
       "    0.01500930916517973,\n",
       "    0.019164886325597763,\n",
       "    0.00909104011952877,\n",
       "    0.01674083061516285,\n",
       "    0.010117219761013985,\n",
       "    0.017276549711823463,\n",
       "    0.010509343817830086,\n",
       "    0.005529891233891249,\n",
       "    0.01131743285804987,\n",
       "    0.01016089878976345,\n",
       "    0.01016343291848898,\n",
       "    0.01885213516652584,\n",
       "    0.014737514778971672,\n",
       "    0.014753777533769608,\n",
       "    0.013238025829195976,\n",
       "    0.012715062126517296,\n",
       "    0.013217954896390438,\n",
       "    0.010060333646833897,\n",
       "    0.015446493402123451,\n",
       "    0.011320773512125015,\n",
       "    0.009246740490198135,\n",
       "    0.014435699209570885,\n",
       "    0.008654766716063023,\n",
       "    0.00780197698622942,\n",
       "    0.016452861949801445,\n",
       "    0.015305212698876858,\n",
       "    0.013707537204027176,\n",
       "    0.009474437683820724,\n",
       "    0.010939357802271843,\n",
       "    0.015706481412053108,\n",
       "    0.012756209820508957,\n",
       "    0.01156284287571907,\n",
       "    0.009282982908189297,\n",
       "    0.007643471471965313,\n",
       "    0.012005940079689026,\n",
       "    0.006961644161492586,\n",
       "    0.009329646825790405,\n",
       "    0.012238366529345512,\n",
       "    0.007417312823235989,\n",
       "    0.011557633988559246,\n",
       "    0.00822532456368208,\n",
       "    0.01031117606908083,\n",
       "    0.014825546182692051,\n",
       "    0.01467119250446558,\n",
       "    0.013225591741502285,\n",
       "    0.014253553934395313,\n",
       "    0.01264038123190403,\n",
       "    0.011679627932608128,\n",
       "    0.015106061473488808,\n",
       "    0.013159072957932949,\n",
       "    0.011591940186917782,\n",
       "    0.01253109984099865,\n",
       "    0.011581535451114178,\n",
       "    0.014805756509304047,\n",
       "    0.01017400436103344,\n",
       "    0.008413221687078476,\n",
       "    0.01823933608829975,\n",
       "    0.013399039395153522,\n",
       "    0.011106226593255997,\n",
       "    0.015077698975801468,\n",
       "    0.0080100791528821,\n",
       "    0.009596345946192741,\n",
       "    0.010983980260789394,\n",
       "    0.01223033107817173,\n",
       "    0.011651146225631237,\n",
       "    0.007216190919280052,\n",
       "    0.009819958359003067,\n",
       "    0.013328873552381992,\n",
       "    0.012633740901947021,\n",
       "    0.009406684897840023,\n",
       "    0.012514140456914902,\n",
       "    0.013231978751718998,\n",
       "    0.011179679073393345,\n",
       "    0.012123316526412964,\n",
       "    0.012094407342374325,\n",
       "    0.013463682495057583,\n",
       "    0.016823602840304375,\n",
       "    0.0074270013719797134,\n",
       "    0.00971653126180172,\n",
       "    0.012882710434496403,\n",
       "    0.010725951753556728,\n",
       "    0.016710182651877403,\n",
       "    0.016606207937002182,\n",
       "    0.00924265943467617,\n",
       "    0.013654300943017006,\n",
       "    0.0094101931899786,\n",
       "    0.007371979765594006,\n",
       "    0.016799528151750565,\n",
       "    0.012856080196797848,\n",
       "    0.007917897775769234,\n",
       "    0.009563938714563847,\n",
       "    0.013800478540360928,\n",
       "    0.01362172793596983,\n",
       "    0.008594800718128681,\n",
       "    0.013777031563222408,\n",
       "    0.009069658815860748,\n",
       "    0.011092633940279484,\n",
       "    0.01215953379869461,\n",
       "    0.014355404302477837,\n",
       "    0.013159376569092274,\n",
       "    0.013608445413410664,\n",
       "    0.010936680249869823,\n",
       "    0.010475574992597103,\n",
       "    0.010766221210360527,\n",
       "    0.011374474503099918,\n",
       "    0.007430543191730976,\n",
       "    0.011649632826447487,\n",
       "    0.011644511483609676,\n",
       "    0.011739619076251984,\n",
       "    0.011600767262279987,\n",
       "    0.01364068128168583,\n",
       "    0.01188569888472557,\n",
       "    0.012114585377275944,\n",
       "    0.007515295408666134,\n",
       "    0.010244508273899555,\n",
       "    0.008592423051595688,\n",
       "    0.010866423137485981,\n",
       "    0.011874070391058922,\n",
       "    0.012835430912673473,\n",
       "    0.017950180917978287,\n",
       "    0.009229457937180996,\n",
       "    0.010695328935980797,\n",
       "    0.005684226751327515,\n",
       "    0.014997155405580997,\n",
       "    0.008084631524980068,\n",
       "    0.01130221039056778,\n",
       "    0.012686184607446194,\n",
       "    0.011335224844515324,\n",
       "    0.015173463150858879,\n",
       "    0.013149799779057503,\n",
       "    0.010284419171512127,\n",
       "    0.008623078465461731,\n",
       "    0.01502813771367073,\n",
       "    0.011941585689783096,\n",
       "    0.016021398827433586,\n",
       "    0.008538604713976383,\n",
       "    0.011572890914976597,\n",
       "    0.014291608706116676,\n",
       "    0.01272197812795639,\n",
       "    0.012457040138542652,\n",
       "    0.015401550568640232,\n",
       "    0.01176754105836153,\n",
       "    0.009189605712890625,\n",
       "    0.010781710036098957,\n",
       "    0.009497659280896187,\n",
       "    0.015546259470283985,\n",
       "    0.011646674014627934,\n",
       "    0.014489647932350636,\n",
       "    0.014086042530834675,\n",
       "    0.012343199923634529,\n",
       "    0.006669411435723305,\n",
       "    0.010397153906524181,\n",
       "    0.011715427972376347,\n",
       "    0.009251373820006847,\n",
       "    0.01605628989636898,\n",
       "    0.010206426493823528,\n",
       "    0.014029079116880894,\n",
       "    0.011305478401482105,\n",
       "    0.012555107474327087,\n",
       "    0.013016278855502605,\n",
       "    0.009205451235175133,\n",
       "    0.010926512070000172,\n",
       "    0.011223900131881237,\n",
       "    0.013287977315485477,\n",
       "    0.018970828503370285,\n",
       "    0.010903303511440754,\n",
       "    0.016419028863310814,\n",
       "    0.013317161239683628,\n",
       "    0.011287087574601173,\n",
       "    0.011152944527566433]}),\n",
       " (LogisticRegression3H(\n",
       "    (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (ac1): Sigmoid()\n",
       "    (fc2): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (ac2): Sigmoid()\n",
       "    (fc3): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (ac3): Sigmoid()\n",
       "    (fc4): Linear(in_features=784, out_features=10, bias=True)\n",
       "  ),\n",
       "  {'fc1.weight': [5.6033654800558e-06,\n",
       "    5.683467406925047e-06,\n",
       "    5.991998932586284e-06,\n",
       "    5.512762982107233e-06,\n",
       "    6.259431756916456e-06,\n",
       "    5.03450064570643e-06,\n",
       "    4.824059033126105e-06,\n",
       "    6.252281764318468e-06,\n",
       "    5.2749101087101735e-06,\n",
       "    5.807568413729314e-06,\n",
       "    4.984644419891993e-06,\n",
       "    6.295381808740785e-06,\n",
       "    5.0124494919145945e-06,\n",
       "    5.006759693060303e-06,\n",
       "    5.076095931144664e-06,\n",
       "    6.346782811306184e-06,\n",
       "    6.221312560228398e-06,\n",
       "    6.204094916029135e-06,\n",
       "    6.261514045036165e-06,\n",
       "    4.982985046808608e-06,\n",
       "    5.564286766457371e-06,\n",
       "    5.747550403611967e-06,\n",
       "    5.0813291636586655e-06,\n",
       "    5.2282043725426774e-06,\n",
       "    5.174016678211046e-06,\n",
       "    6.006177500239573e-06,\n",
       "    4.96576512887259e-06,\n",
       "    5.321637672750512e-06,\n",
       "    5.075490662420634e-06,\n",
       "    5.608951141766738e-06,\n",
       "    6.086711437092163e-06,\n",
       "    5.539057838177541e-06,\n",
       "    5.524317657545907e-06,\n",
       "    5.343243174138479e-06,\n",
       "    5.354198492568685e-06,\n",
       "    5.444544513011351e-06,\n",
       "    5.5043510656105354e-06,\n",
       "    5.704333489120472e-06,\n",
       "    5.538289769901894e-06,\n",
       "    6.268219749472337e-06,\n",
       "    5.2259374569985084e-06,\n",
       "    5.474510544445366e-06,\n",
       "    4.509951395448297e-06,\n",
       "    5.583305664913496e-06,\n",
       "    6.314139682217501e-06,\n",
       "    5.244993644737406e-06,\n",
       "    5.716653959098039e-06,\n",
       "    4.876287221122766e-06,\n",
       "    5.867943400517106e-06,\n",
       "    4.973370323568815e-06,\n",
       "    4.8185324885707814e-06,\n",
       "    5.118647095514461e-06,\n",
       "    5.628440248983679e-06,\n",
       "    4.903351964458125e-06,\n",
       "    5.205457000556635e-06,\n",
       "    5.994590537738986e-06,\n",
       "    5.083397354610497e-06,\n",
       "    5.843161488883197e-06,\n",
       "    6.328486961137969e-06,\n",
       "    6.370215487550013e-06,\n",
       "    5.074051841802429e-06,\n",
       "    6.091624072723789e-06,\n",
       "    6.1862601796747185e-06,\n",
       "    5.126154974277597e-06,\n",
       "    5.438138032332063e-06,\n",
       "    5.214663360675331e-06,\n",
       "    5.237405730440514e-06,\n",
       "    5.706850060960278e-06,\n",
       "    5.628162853099639e-06,\n",
       "    4.922272637486458e-06,\n",
       "    5.870914719707798e-06,\n",
       "    5.940252322034212e-06,\n",
       "    6.2254762269731145e-06,\n",
       "    4.568966232909588e-06,\n",
       "    4.802860985364532e-06,\n",
       "    5.138282176631037e-06,\n",
       "    5.416240583144827e-06,\n",
       "    5.324942776496755e-06,\n",
       "    6.157762982184067e-06,\n",
       "    5.181329470360652e-06,\n",
       "    5.055083875049604e-06,\n",
       "    5.984346444165567e-06,\n",
       "    5.4708225434296764e-06,\n",
       "    4.691806225309847e-06,\n",
       "    6.364972705341643e-06,\n",
       "    5.507255082193296e-06,\n",
       "    7.040561285975855e-06,\n",
       "    5.517538738786243e-06,\n",
       "    5.717588919651462e-06,\n",
       "    6.487129212473519e-06,\n",
       "    5.805415185022866e-06,\n",
       "    5.0897342589451e-06,\n",
       "    6.170247615955304e-06,\n",
       "    5.091212187835481e-06,\n",
       "    5.010529548599152e-06,\n",
       "    5.839574441779405e-06,\n",
       "    5.213527401792817e-06,\n",
       "    5.838080141984392e-06,\n",
       "    5.949789738224354e-06,\n",
       "    6.557355845870916e-06,\n",
       "    6.314351139735663e-06,\n",
       "    6.033230420143809e-06,\n",
       "    4.850872755923774e-06,\n",
       "    5.135158517077798e-06,\n",
       "    5.693174443877069e-06,\n",
       "    5.083353244117461e-06,\n",
       "    5.404690909927012e-06,\n",
       "    4.894534413324436e-06,\n",
       "    5.744795998907648e-06,\n",
       "    6.632157692365581e-06,\n",
       "    6.0049833336961456e-06,\n",
       "    5.701822374248877e-06,\n",
       "    5.070427505415864e-06,\n",
       "    5.2828208936261944e-06,\n",
       "    5.850958586961497e-06,\n",
       "    5.131063517183065e-06,\n",
       "    5.822556431667181e-06,\n",
       "    4.938818165101111e-06,\n",
       "    5.76056118006818e-06,\n",
       "    5.306682396621909e-06,\n",
       "    5.091789716971107e-06,\n",
       "    5.289463842927944e-06,\n",
       "    5.219132617639843e-06,\n",
       "    5.02693410453503e-06,\n",
       "    5.814796622871654e-06,\n",
       "    5.334162779035978e-06,\n",
       "    4.607202754414175e-06,\n",
       "    4.791274932358647e-06,\n",
       "    5.370662165660178e-06,\n",
       "    5.752997822128236e-06,\n",
       "    5.843564395036083e-06,\n",
       "    5.895489721297054e-06,\n",
       "    5.797025551146362e-06,\n",
       "    4.820421509066364e-06,\n",
       "    5.430075361800846e-06,\n",
       "    6.0606012084463146e-06,\n",
       "    5.491916908795247e-06,\n",
       "    5.342296390153933e-06,\n",
       "    5.098191195429536e-06,\n",
       "    5.4105325943965e-06,\n",
       "    5.479488208948169e-06,\n",
       "    5.601890734396875e-06,\n",
       "    4.546976015262771e-06,\n",
       "    6.302801466517849e-06,\n",
       "    5.4054235079092905e-06,\n",
       "    5.928378413955215e-06,\n",
       "    5.829961992276367e-06,\n",
       "    5.18195975018898e-06,\n",
       "    5.019232503400417e-06,\n",
       "    5.211787538428325e-06,\n",
       "    5.7784268392424565e-06,\n",
       "    6.318605301203206e-06,\n",
       "    5.491299816640094e-06,\n",
       "    5.344964392861584e-06,\n",
       "    6.106085038481979e-06,\n",
       "    5.827610493724933e-06,\n",
       "    5.28223881701706e-06,\n",
       "    5.126494670548709e-06,\n",
       "    6.663309250143357e-06,\n",
       "    5.881212018721271e-06,\n",
       "    5.66672997592832e-06,\n",
       "    6.023589776305016e-06,\n",
       "    5.107618562760763e-06,\n",
       "    5.653006610373268e-06,\n",
       "    4.413474016473629e-06,\n",
       "    5.009329015592812e-06,\n",
       "    5.3102089623280335e-06,\n",
       "    4.895712663710583e-06,\n",
       "    6.050256615708349e-06,\n",
       "    5.695587333320873e-06,\n",
       "    5.025570771977073e-06,\n",
       "    5.049921583122341e-06,\n",
       "    5.291657998895971e-06,\n",
       "    5.542053713725181e-06,\n",
       "    5.648279511660803e-06,\n",
       "    6.3056349972612225e-06,\n",
       "    4.973101113137091e-06,\n",
       "    5.042933480581269e-06,\n",
       "    5.592767593043391e-06,\n",
       "    5.34871742274845e-06,\n",
       "    5.042731572757475e-06,\n",
       "    5.164414687897079e-06,\n",
       "    4.814713520318037e-06,\n",
       "    4.586986506183166e-06,\n",
       "    4.930075647280319e-06,\n",
       "    5.118481567478739e-06,\n",
       "    5.692860213457607e-06,\n",
       "    5.8660589274950325e-06,\n",
       "    5.123691607877845e-06,\n",
       "    5.066764515504474e-06,\n",
       "    5.192213848204119e-06,\n",
       "    5.372923624236137e-06,\n",
       "    5.3433450375450775e-06,\n",
       "    5.521827461052453e-06,\n",
       "    6.553663752129069e-06,\n",
       "    5.55668884771876e-06,\n",
       "    5.316713213687763e-06,\n",
       "    4.7718581299704965e-06,\n",
       "    4.628185706678778e-06,\n",
       "    5.406441232480574e-06,\n",
       "    5.8731807257572655e-06,\n",
       "    6.122309514466906e-06,\n",
       "    5.47154240848613e-06,\n",
       "    5.923047410760773e-06,\n",
       "    5.7761517382459715e-06,\n",
       "    4.7949206418707035e-06,\n",
       "    5.37098094355315e-06,\n",
       "    5.00053556606872e-06,\n",
       "    4.898639872408239e-06,\n",
       "    5.2771251830563415e-06,\n",
       "    5.3638364079233725e-06,\n",
       "    5.93612185184611e-06,\n",
       "    6.089516773499781e-06,\n",
       "    5.595416496362304e-06,\n",
       "    5.212087216932559e-06,\n",
       "    5.8011009969050065e-06,\n",
       "    5.117331511428347e-06,\n",
       "    5.4954912229732145e-06,\n",
       "    5.104068350192392e-06,\n",
       "    5.086253622721415e-06,\n",
       "    5.693526418326655e-06,\n",
       "    5.156768111191923e-06,\n",
       "    5.8663072195486166e-06,\n",
       "    6.023607966199052e-06,\n",
       "    5.886450708203483e-06,\n",
       "    5.740480901295086e-06,\n",
       "    5.071675332146697e-06,\n",
       "    4.786917543242453e-06,\n",
       "    4.894073754257988e-06,\n",
       "    5.911168045713566e-06,\n",
       "    5.591436092799995e-06,\n",
       "    5.4950023695710115e-06,\n",
       "    6.237074103410123e-06,\n",
       "    4.8490405788470525e-06,\n",
       "    6.060059604351409e-06,\n",
       "    4.400625584821682e-06,\n",
       "    4.627805992640788e-06,\n",
       "    4.479996732698055e-06,\n",
       "    4.453686869965168e-06,\n",
       "    5.2518953452818096e-06,\n",
       "    5.2689460972032975e-06,\n",
       "    4.874393198406324e-06,\n",
       "    5.094083917356329e-06,\n",
       "    5.9985832194797695e-06,\n",
       "    6.4352107074228115e-06,\n",
       "    5.9394487834651954e-06,\n",
       "    5.94423227084917e-06,\n",
       "    5.059753220848506e-06,\n",
       "    4.958822046319256e-06,\n",
       "    5.173844783712411e-06,\n",
       "    5.197013251745375e-06,\n",
       "    4.816154159925645e-06,\n",
       "    4.78689071314875e-06,\n",
       "    5.422735739557538e-06,\n",
       "    4.699115379480645e-06,\n",
       "    5.226310804573586e-06,\n",
       "    5.771624728367897e-06,\n",
       "    6.0828747336927336e-06,\n",
       "    5.014595444663428e-06,\n",
       "    5.099368536320981e-06,\n",
       "    5.924382094235625e-06,\n",
       "    5.4991919569147285e-06,\n",
       "    5.803006843052572e-06,\n",
       "    4.415524472278776e-06,\n",
       "    4.785851615451975e-06,\n",
       "    5.127883468958316e-06,\n",
       "    5.554724339162931e-06,\n",
       "    5.580483048106544e-06,\n",
       "    5.183740086067701e-06,\n",
       "    5.9184885685681365e-06,\n",
       "    5.203770342632197e-06,\n",
       "    5.425475592346629e-06,\n",
       "    5.069322014605859e-06,\n",
       "    4.948483365296852e-06,\n",
       "    5.086150849820115e-06,\n",
       "    5.826519100082805e-06,\n",
       "    5.752702691097511e-06,\n",
       "    5.5461064221162815e-06,\n",
       "    5.08765151607804e-06,\n",
       "    5.864379545528209e-06,\n",
       "    5.425472409115173e-06,\n",
       "    6.763469173165504e-06,\n",
       "    5.022279765398707e-06,\n",
       "    5.882274308532942e-06,\n",
       "    5.656760549754836e-06,\n",
       "    5.69909479963826e-06,\n",
       "    5.120335117680952e-06,\n",
       "    4.876702860201476e-06,\n",
       "    5.370425697037717e-06,\n",
       "    5.240583504928509e-06,\n",
       "    5.432024863694096e-06,\n",
       "    5.360263003240107e-06,\n",
       "    5.181808319321135e-06,\n",
       "    5.525389497051947e-06,\n",
       "    5.071854047855595e-06,\n",
       "    4.738696588901803e-06,\n",
       "    5.981138201605063e-06,\n",
       "    5.259240424493328e-06,\n",
       "    4.979407549399184e-06,\n",
       "    5.9424805840535555e-06,\n",
       "    5.678099569195183e-06,\n",
       "    5.387021246860968e-06,\n",
       "    5.723880803998327e-06,\n",
       "    5.1680362957995385e-06,\n",
       "    5.8476748563407455e-06,\n",
       "    6.062586635380285e-06,\n",
       "    5.040407813794445e-06,\n",
       "    5.9152562243980356e-06,\n",
       "    5.514021722774487e-06,\n",
       "    5.781644631497329e-06,\n",
       "    5.224918822932523e-06,\n",
       "    5.477689683175413e-06,\n",
       "    4.983051894669188e-06,\n",
       "    6.060245596017921e-06,\n",
       "    5.3601675062964205e-06,\n",
       "    5.845202849741327e-06,\n",
       "    6.248173122003209e-06,\n",
       "    4.910285497317091e-06,\n",
       "    5.334118213795591e-06,\n",
       "    4.92875278723659e-06,\n",
       "    5.2449822760536335e-06,\n",
       "    5.140220309840515e-06,\n",
       "    5.759648502134951e-06,\n",
       "    4.70507393401931e-06,\n",
       "    5.268987024464877e-06,\n",
       "    5.571890142164193e-06,\n",
       "    5.5660048019490205e-06,\n",
       "    5.340178631740855e-06,\n",
       "    5.584048267337494e-06,\n",
       "    5.724565653508762e-06,\n",
       "    5.4271281442197505e-06,\n",
       "    6.779567684134236e-06,\n",
       "    6.932536507520126e-06,\n",
       "    5.1010956667596474e-06,\n",
       "    5.491869615070755e-06,\n",
       "    5.415729901869781e-06,\n",
       "    5.004053036827827e-06,\n",
       "    5.381576556828804e-06,\n",
       "    5.162808520253748e-06,\n",
       "    4.781718871527119e-06,\n",
       "    5.560537829296663e-06,\n",
       "    5.2916843742423225e-06,\n",
       "    5.504075488715898e-06,\n",
       "    5.068525297247106e-06,\n",
       "    5.342953954823315e-06,\n",
       "    4.935143806505948e-06,\n",
       "    5.599582436843775e-06,\n",
       "    5.203652563068317e-06,\n",
       "    5.703289843950188e-06,\n",
       "    5.3555659178528e-06,\n",
       "    6.046772796253208e-06,\n",
       "    4.926289875584189e-06,\n",
       "    4.884573172603268e-06,\n",
       "    6.328941253741505e-06,\n",
       "    7.558839570265263e-06,\n",
       "    4.8154042815440334e-06,\n",
       "    5.4866995924385265e-06,\n",
       "    5.536748176382389e-06,\n",
       "    5.7122706493828446e-06,\n",
       "    5.2182908802933525e-06,\n",
       "    5.2060026973776985e-06,\n",
       "    5.84441477258224e-06,\n",
       "    5.9084113672724925e-06,\n",
       "    5.052669621363748e-06,\n",
       "    5.720102763007162e-06],\n",
       "   'fc2.weight': [4.118065771763213e-05,\n",
       "    3.0319239158416167e-05,\n",
       "    4.079267819179222e-05,\n",
       "    3.986458614235744e-05,\n",
       "    4.68440011900384e-05,\n",
       "    3.8863483496243134e-05,\n",
       "    4.0429458749713376e-05,\n",
       "    4.7094086767174304e-05,\n",
       "    4.0990315028466284e-05,\n",
       "    4.222956704325043e-05,\n",
       "    2.796700573526323e-05,\n",
       "    5.110491838422604e-05,\n",
       "    2.9062828616588376e-05,\n",
       "    3.183472290402278e-05,\n",
       "    2.932658935606014e-05,\n",
       "    4.4100292143411934e-05,\n",
       "    4.1505747503833845e-05,\n",
       "    4.24068421125412e-05,\n",
       "    5.231043178355321e-05,\n",
       "    2.2763322704122402e-05,\n",
       "    2.9215221729828045e-05,\n",
       "    3.3937885746126994e-05,\n",
       "    3.19573882734403e-05,\n",
       "    3.30235852743499e-05,\n",
       "    3.505094355205074e-05,\n",
       "    4.192431515548378e-05,\n",
       "    3.999191176262684e-05,\n",
       "    3.5830835258821025e-05,\n",
       "    4.0890517993830144e-05,\n",
       "    2.955689706141129e-05,\n",
       "    4.222098141326569e-05,\n",
       "    4.027898467029445e-05,\n",
       "    3.5288958315504715e-05,\n",
       "    3.337191083119251e-05,\n",
       "    4.019532207166776e-05,\n",
       "    3.353838110342622e-05,\n",
       "    3.8060392398620024e-05,\n",
       "    4.043123044539243e-05,\n",
       "    3.7560857890639454e-05,\n",
       "    4.3497657316038385e-05,\n",
       "    2.8704607757390477e-05,\n",
       "    3.251307498430833e-05,\n",
       "    2.6676705601857975e-05,\n",
       "    3.653483508969657e-05,\n",
       "    4.5431330363499e-05,\n",
       "    3.8868111005285755e-05,\n",
       "    4.27419290645048e-05,\n",
       "    3.959474270232022e-05,\n",
       "    4.6258297516033053e-05,\n",
       "    2.8514343284768984e-05,\n",
       "    3.456702324911021e-05,\n",
       "    3.662114977487363e-05,\n",
       "    3.589566767914221e-05,\n",
       "    2.582042543508578e-05,\n",
       "    2.9434853786369786e-05,\n",
       "    3.960271715186536e-05,\n",
       "    3.1189618312055245e-05,\n",
       "    3.740268948604353e-05,\n",
       "    4.74962689622771e-05,\n",
       "    3.962105620303191e-05,\n",
       "    3.845890751108527e-05,\n",
       "    4.024538793601096e-05,\n",
       "    4.7647285100538284e-05,\n",
       "    3.475016274023801e-05,\n",
       "    4.063639062223956e-05,\n",
       "    3.296844442957081e-05,\n",
       "    3.612087675719522e-05,\n",
       "    3.692192694870755e-05,\n",
       "    4.260036439518444e-05,\n",
       "    3.231050868635066e-05,\n",
       "    3.730561365955509e-05,\n",
       "    4.324175461078994e-05,\n",
       "    4.3741820263676345e-05,\n",
       "    2.1812924387631938e-05,\n",
       "    2.976118412334472e-05,\n",
       "    3.0471102945739403e-05,\n",
       "    4.25919824920129e-05,\n",
       "    3.419527274672873e-05,\n",
       "    4.930224167765118e-05,\n",
       "    2.7670454073813744e-05,\n",
       "    2.951590249722358e-05,\n",
       "    4.442788122105412e-05,\n",
       "    3.024238503712695e-05,\n",
       "    3.39340913342312e-05,\n",
       "    5.171804514247924e-05,\n",
       "    4.264821836841293e-05,\n",
       "    4.598546729539521e-05,\n",
       "    3.897110582329333e-05,\n",
       "    5.3017138270661235e-05,\n",
       "    4.158348747296259e-05,\n",
       "    4.053529482916929e-05,\n",
       "    2.6775249352795072e-05,\n",
       "    4.511186125455424e-05,\n",
       "    3.4008597140200436e-05,\n",
       "    2.9488399377441965e-05,\n",
       "    3.846806430374272e-05,\n",
       "    3.1728279282106087e-05,\n",
       "    4.026892565889284e-05,\n",
       "    4.2896484956145287e-05,\n",
       "    4.8442354454891756e-05,\n",
       "    4.530196383711882e-05,\n",
       "    3.972546255681664e-05,\n",
       "    2.8304264560574666e-05,\n",
       "    2.718310679483693e-05,\n",
       "    4.821617403649725e-05,\n",
       "    3.602462311391719e-05,\n",
       "    3.484274566289969e-05,\n",
       "    3.547135929693468e-05,\n",
       "    4.204130163998343e-05,\n",
       "    4.421091580297798e-05,\n",
       "    5.030841930420138e-05,\n",
       "    2.935258817160502e-05,\n",
       "    4.430150147527456e-05,\n",
       "    3.344314973219298e-05,\n",
       "    3.286042920080945e-05,\n",
       "    4.2743715312099084e-05,\n",
       "    3.7785845051985234e-05,\n",
       "    2.090812813548837e-05,\n",
       "    3.9831131289247423e-05,\n",
       "    4.054659802932292e-05,\n",
       "    2.425250568194315e-05,\n",
       "    3.951223334297538e-05,\n",
       "    3.689747609314509e-05,\n",
       "    2.7504254831001163e-05,\n",
       "    4.101043668924831e-05,\n",
       "    3.2571675546932966e-05,\n",
       "    2.521776332287118e-05,\n",
       "    3.1878425943432376e-05,\n",
       "    3.560678305802867e-05,\n",
       "    3.740048487088643e-05,\n",
       "    3.726137583726086e-05,\n",
       "    3.53514333255589e-05,\n",
       "    4.342089960118756e-05,\n",
       "    3.7016565329395235e-05,\n",
       "    3.2256361009785905e-05,\n",
       "    3.545677463989705e-05,\n",
       "    4.076297045685351e-05,\n",
       "    2.9769978937110864e-05,\n",
       "    3.3518019336042926e-05,\n",
       "    4.067780537297949e-05,\n",
       "    3.82798898499459e-05,\n",
       "    3.832254515145905e-05,\n",
       "    1.6907306417124346e-05,\n",
       "    4.78382789879106e-05,\n",
       "    3.897328861057758e-05,\n",
       "    3.6827754229307175e-05,\n",
       "    3.653155727079138e-05,\n",
       "    3.940843089367263e-05,\n",
       "    2.662826591404155e-05,\n",
       "    2.965634485008195e-05,\n",
       "    3.825010571745224e-05,\n",
       "    4.2686086089815944e-05,\n",
       "    3.4601274819578975e-05,\n",
       "    3.607974940678105e-05,\n",
       "    4.3235970224486664e-05,\n",
       "    4.080039434484206e-05,\n",
       "    3.55598094756715e-05,\n",
       "    3.376735185156576e-05,\n",
       "    4.873576108366251e-05,\n",
       "    4.853870996157639e-05,\n",
       "    3.5963832488050684e-05,\n",
       "    4.6755689254496247e-05,\n",
       "    3.1060611945576966e-05,\n",
       "    3.475392804830335e-05,\n",
       "    3.05421490338631e-05,\n",
       "    3.2419353374280035e-05,\n",
       "    3.2291725801769644e-05,\n",
       "    3.0047856853343546e-05,\n",
       "    3.995950100943446e-05,\n",
       "    3.8687929190928116e-05,\n",
       "    3.695619307109155e-05,\n",
       "    2.943879007943906e-05,\n",
       "    3.748757080757059e-05,\n",
       "    3.592567009036429e-05,\n",
       "    3.444260801188648e-05,\n",
       "    4.975581759936176e-05,\n",
       "    2.8578338969964534e-05,\n",
       "    3.219073551008478e-05,\n",
       "    3.08043381664902e-05,\n",
       "    4.402061676955782e-05,\n",
       "    3.1659594242228195e-05,\n",
       "    3.165611269650981e-05,\n",
       "    2.219859743490815e-05,\n",
       "    2.9362070563365705e-05,\n",
       "    2.1033496523159556e-05,\n",
       "    3.7465324567165226e-05,\n",
       "    4.7759876906638965e-05,\n",
       "    5.107093238621019e-05,\n",
       "    2.1381047190516256e-05,\n",
       "    2.833777034538798e-05,\n",
       "    3.561702396837063e-05,\n",
       "    2.9366343369474635e-05,\n",
       "    3.400450077606365e-05,\n",
       "    3.670658406917937e-05,\n",
       "    4.5041069824947044e-05,\n",
       "    4.4242780859349295e-05,\n",
       "    3.5726236092159525e-05,\n",
       "    3.745113281183876e-05,\n",
       "    2.8978112823097035e-05,\n",
       "    3.1962536013452336e-05,\n",
       "    4.560317756840959e-05,\n",
       "    4.74202424811665e-05,\n",
       "    3.161406857543625e-05,\n",
       "    4.0022077882895246e-05,\n",
       "    4.1539573430782184e-05,\n",
       "    3.5485310945659876e-05,\n",
       "    2.791161932691466e-05,\n",
       "    3.61653437721543e-05,\n",
       "    2.4081853553070687e-05,\n",
       "    3.3605621865717694e-05,\n",
       "    3.073803600273095e-05,\n",
       "    4.000497574452311e-05,\n",
       "    4.715299655799754e-05,\n",
       "    3.37561868946068e-05,\n",
       "    3.39178805006668e-05,\n",
       "    4.09667773055844e-05,\n",
       "    3.215266769984737e-05,\n",
       "    3.1777781259734184e-05,\n",
       "    3.658867353806272e-05,\n",
       "    3.0728486308362335e-05,\n",
       "    4.387907756608911e-05,\n",
       "    3.242579259676859e-05,\n",
       "    5.044117278885096e-05,\n",
       "    4.3263975385343656e-05,\n",
       "    4.4368134695105255e-05,\n",
       "    3.621331416070461e-05,\n",
       "    3.1497253075940534e-05,\n",
       "    2.7576650609262288e-05,\n",
       "    3.235746407881379e-05,\n",
       "    3.6648387322202325e-05,\n",
       "    3.8732912798877805e-05,\n",
       "    2.8210921300342306e-05,\n",
       "    3.8305341149680316e-05,\n",
       "    3.4934040741063654e-05,\n",
       "    4.555709529086016e-05,\n",
       "    3.470011506578885e-05,\n",
       "    2.945857158920262e-05,\n",
       "    2.906221925513819e-05,\n",
       "    2.223543378931936e-05,\n",
       "    3.0396087822737172e-05,\n",
       "    3.317092341603711e-05,\n",
       "    3.9421520341420546e-05,\n",
       "    2.394805233052466e-05,\n",
       "    4.36272966908291e-05,\n",
       "    4.487876140046865e-05,\n",
       "    4.0662129322299734e-05,\n",
       "    5.5627944675507024e-05,\n",
       "    2.794251668092329e-05,\n",
       "    3.135637962259352e-05,\n",
       "    3.814083902398124e-05,\n",
       "    3.642913725343533e-05,\n",
       "    2.4226865207310766e-05,\n",
       "    2.410714478173759e-05,\n",
       "    4.083364910911769e-05,\n",
       "    2.4734339604037814e-05,\n",
       "    4.991272362531163e-05,\n",
       "    3.8754893466830254e-05,\n",
       "    4.1800871258601546e-05,\n",
       "    3.7852980312891304e-05,\n",
       "    3.244812251068652e-05,\n",
       "    4.357375291874632e-05,\n",
       "    3.787342575378716e-05,\n",
       "    3.354608634253964e-05,\n",
       "    2.235989632026758e-05,\n",
       "    2.8720054615405388e-05,\n",
       "    3.6467306927079335e-05,\n",
       "    3.511771865305491e-05,\n",
       "    3.366032979101874e-05,\n",
       "    3.6492849176283926e-05,\n",
       "    3.882076998706907e-05,\n",
       "    3.203789674444124e-05,\n",
       "    4.033719960716553e-05,\n",
       "    3.474236655165441e-05,\n",
       "    3.2793148420751095e-05,\n",
       "    2.7819713068311103e-05,\n",
       "    4.246803655405529e-05,\n",
       "    3.885961996275e-05,\n",
       "    4.3375017412472516e-05,\n",
       "    2.7992560717393644e-05,\n",
       "    4.161163087701425e-05,\n",
       "    3.524512067087926e-05,\n",
       "    4.406458174344152e-05,\n",
       "    2.7739641154767014e-05,\n",
       "    3.903316974174231e-05,\n",
       "    3.549399843905121e-05,\n",
       "    4.1202740248991176e-05,\n",
       "    4.128405635128729e-05,\n",
       "    3.214511161786504e-05,\n",
       "    3.2324711355613545e-05,\n",
       "    3.5348137316759676e-05,\n",
       "    4.34789399150759e-05,\n",
       "    2.653532828844618e-05,\n",
       "    3.119161192444153e-05,\n",
       "    3.171052594552748e-05,\n",
       "    3.7867579521844164e-05,\n",
       "    2.8623609978239983e-05,\n",
       "    3.9925023884279653e-05,\n",
       "    3.215949618606828e-05,\n",
       "    2.5281209673266858e-05,\n",
       "    3.6942325095878914e-05,\n",
       "    3.84964732802473e-05,\n",
       "    4.312110104365274e-05,\n",
       "    4.062677180627361e-05,\n",
       "    3.472339085419662e-05,\n",
       "    4.4797892769565806e-05,\n",
       "    4.4112635805504397e-05,\n",
       "    4.1138457163469866e-05,\n",
       "    3.6934579838998616e-05,\n",
       "    3.0036693715373985e-05,\n",
       "    3.836134055745788e-05,\n",
       "    3.544211358530447e-05,\n",
       "    3.1566363759338856e-05,\n",
       "    3.2435327739221975e-05,\n",
       "    4.9867230700328946e-05,\n",
       "    4.111089583602734e-05,\n",
       "    5.237812001723796e-05,\n",
       "    5.002891339245252e-05,\n",
       "    3.1803421734366566e-05,\n",
       "    4.053588054375723e-05,\n",
       "    3.705320705194026e-05,\n",
       "    2.848503390850965e-05,\n",
       "    3.452422970440239e-05,\n",
       "    3.565354927559383e-05,\n",
       "    2.9836339308531024e-05,\n",
       "    2.9587683457066305e-05,\n",
       "    4.409420216688886e-05,\n",
       "    3.5221073630964383e-05,\n",
       "    3.1750958441989496e-05,\n",
       "    3.1908337405184284e-05,\n",
       "    3.517684308462776e-05,\n",
       "    3.1525771191809326e-05,\n",
       "    5.101519127492793e-05,\n",
       "    5.3378058510133997e-05,\n",
       "    3.5089626180706546e-05,\n",
       "    3.6394118069438264e-05,\n",
       "    4.1509199945721775e-05,\n",
       "    2.9059867301839404e-05,\n",
       "    3.325682700960897e-05,\n",
       "    3.5740871680900455e-05,\n",
       "    2.786725599435158e-05,\n",
       "    3.8921949453651905e-05,\n",
       "    3.516358992783353e-05,\n",
       "    3.580142220016569e-05,\n",
       "    2.7295091058476828e-05,\n",
       "    3.4293840144528076e-05,\n",
       "    2.508752186258789e-05,\n",
       "    3.899049261235632e-05,\n",
       "    3.3214837458217517e-05,\n",
       "    3.181573629262857e-05,\n",
       "    3.318526069051586e-05,\n",
       "    4.0746537706581876e-05,\n",
       "    2.8731483325827867e-05,\n",
       "    3.5553035559132695e-05,\n",
       "    4.50695697509218e-05,\n",
       "    6.017357009113766e-05,\n",
       "    2.583008972578682e-05,\n",
       "    3.161657878081314e-05,\n",
       "    4.11273940699175e-05,\n",
       "    3.980029214289971e-05,\n",
       "    2.7498321287566796e-05,\n",
       "    4.264486051397398e-05,\n",
       "    4.2290812416467816e-05,\n",
       "    3.9252961869351566e-05,\n",
       "    3.6215613363310695e-05,\n",
       "    4.893000004813075e-05],\n",
       "   'fc3.weight': [0.00028591579757630825,\n",
       "    0.00020966741431038827,\n",
       "    0.0002782551455311477,\n",
       "    0.00026723506744019687,\n",
       "    0.00031776539981365204,\n",
       "    0.0002643472689669579,\n",
       "    0.0002853243495337665,\n",
       "    0.00032459970680065453,\n",
       "    0.00029221648583188653,\n",
       "    0.0003062426985707134,\n",
       "    0.00019208970479667187,\n",
       "    0.00034787305048666894,\n",
       "    0.00019959852215833962,\n",
       "    0.00021534781262744218,\n",
       "    0.00019638813682831824,\n",
       "    0.0002953997754957527,\n",
       "    0.00029681279556825757,\n",
       "    0.0002998058625962585,\n",
       "    0.0003622970834840089,\n",
       "    0.00015523268666584045,\n",
       "    0.00020509301975835115,\n",
       "    0.00022836962307337672,\n",
       "    0.00021589112293440849,\n",
       "    0.00022625806741416454,\n",
       "    0.00023680389858782291,\n",
       "    0.00028075065347366035,\n",
       "    0.0002711180131882429,\n",
       "    0.00024714661412872374,\n",
       "    0.0002688840904738754,\n",
       "    0.0002132539520971477,\n",
       "    0.00029313768027350307,\n",
       "    0.00027462266734801233,\n",
       "    0.00025305806775577366,\n",
       "    0.0002344734239159152,\n",
       "    0.0002746692334767431,\n",
       "    0.00022477484890259802,\n",
       "    0.0002580186410341412,\n",
       "    0.0002788612328004092,\n",
       "    0.00025472347624599934,\n",
       "    0.00030615294235758483,\n",
       "    0.00019295727543067187,\n",
       "    0.0002303557121194899,\n",
       "    0.0001782601175364107,\n",
       "    0.0002634735719766468,\n",
       "    0.0003132523561362177,\n",
       "    0.0002560011635068804,\n",
       "    0.0002889213792514056,\n",
       "    0.0002743904187809676,\n",
       "    0.0003222955565433949,\n",
       "    0.00019514374434947968,\n",
       "    0.0002256448206026107,\n",
       "    0.00025192747125402093,\n",
       "    0.0002484434808138758,\n",
       "    0.00018066448683384806,\n",
       "    0.0002006449067266658,\n",
       "    0.0002743703662417829,\n",
       "    0.00021284192916937172,\n",
       "    0.0002597691200207919,\n",
       "    0.0003225878463126719,\n",
       "    0.0002629936789162457,\n",
       "    0.00025802318123169243,\n",
       "    0.0002797111519612372,\n",
       "    0.0003319748502690345,\n",
       "    0.00024019047850742936,\n",
       "    0.00027935669641010463,\n",
       "    0.00023223677999339998,\n",
       "    0.00024304586986545473,\n",
       "    0.00025269979960285127,\n",
       "    0.00029400159837678075,\n",
       "    0.00022380526934284717,\n",
       "    0.00025561937945894897,\n",
       "    0.0002985771279782057,\n",
       "    0.00029815229936502874,\n",
       "    0.0001421928609488532,\n",
       "    0.00021191655832808465,\n",
       "    0.00020913174375891685,\n",
       "    0.0002920124679803848,\n",
       "    0.00023587446776218712,\n",
       "    0.000340335100190714,\n",
       "    0.00018342399562243372,\n",
       "    0.00019968108972534537,\n",
       "    0.0002949476765934378,\n",
       "    0.00019888074893970042,\n",
       "    0.00023680053709540516,\n",
       "    0.00036909602931700647,\n",
       "    0.0002966008905787021,\n",
       "    0.00032133658532984555,\n",
       "    0.00027752507594414055,\n",
       "    0.0003779655380640179,\n",
       "    0.00028930543339811265,\n",
       "    0.0002789029967971146,\n",
       "    0.00017974176444113255,\n",
       "    0.0003267541469540447,\n",
       "    0.000236702777328901,\n",
       "    0.0002012470067711547,\n",
       "    0.0002652428229339421,\n",
       "    0.00022049063409212977,\n",
       "    0.00027446000603958964,\n",
       "    0.00029345130315050483,\n",
       "    0.00032805476803332567,\n",
       "    0.00031162239611148834,\n",
       "    0.00027429262991063297,\n",
       "    0.00019651191541925073,\n",
       "    0.0001886491518234834,\n",
       "    0.0003464379988145083,\n",
       "    0.00024979637237265706,\n",
       "    0.0002408609288977459,\n",
       "    0.0002495066437404603,\n",
       "    0.0002826140553224832,\n",
       "    0.0002983662998303771,\n",
       "    0.00034272571792826056,\n",
       "    0.00019874736608471721,\n",
       "    0.00029681622982025146,\n",
       "    0.00023349608818534762,\n",
       "    0.00023004748800303787,\n",
       "    0.00027845779550261796,\n",
       "    0.0002641302125994116,\n",
       "    0.00014229661610443145,\n",
       "    0.00027684002998284996,\n",
       "    0.0002885580761358142,\n",
       "    0.00016877333109732717,\n",
       "    0.0002814043255057186,\n",
       "    0.000256214349064976,\n",
       "    0.000190068079973571,\n",
       "    0.0002874226192943752,\n",
       "    0.00022840507153887302,\n",
       "    0.00017376126197632402,\n",
       "    0.00022108574921730906,\n",
       "    0.0002527615870349109,\n",
       "    0.0002649327798280865,\n",
       "    0.0002514048246666789,\n",
       "    0.0002596212725620717,\n",
       "    0.0002981128345709294,\n",
       "    0.00026056967908516526,\n",
       "    0.00022049534891266376,\n",
       "    0.00024159011081792414,\n",
       "    0.00027608696836978197,\n",
       "    0.00020857338677160442,\n",
       "    0.00022061121126171201,\n",
       "    0.0002862776455003768,\n",
       "    0.00027558565489016473,\n",
       "    0.00027176347794011235,\n",
       "    0.00011537932732608169,\n",
       "    0.0003219285572413355,\n",
       "    0.0002782376832328737,\n",
       "    0.00025861518224701285,\n",
       "    0.00025121407816186547,\n",
       "    0.00027568472432903945,\n",
       "    0.0001816267176764086,\n",
       "    0.0002106006140820682,\n",
       "    0.0002581966982688755,\n",
       "    0.00029226375045254827,\n",
       "    0.00023423953098244965,\n",
       "    0.00024834179203025997,\n",
       "    0.00029794039437547326,\n",
       "    0.00028266775188967586,\n",
       "    0.0002465034485794604,\n",
       "    0.0002381825470365584,\n",
       "    0.0003344626456964761,\n",
       "    0.0003235942276660353,\n",
       "    0.0002631036622915417,\n",
       "    0.0003275212657172233,\n",
       "    0.00021741162345279008,\n",
       "    0.00023821859213057905,\n",
       "    0.00020286622748244554,\n",
       "    0.00021540826128330082,\n",
       "    0.00022589316358789802,\n",
       "    0.00021163422206882387,\n",
       "    0.00027547363424673676,\n",
       "    0.00026930184685625136,\n",
       "    0.00025598503998480737,\n",
       "    0.0002036271325778216,\n",
       "    0.00026633808738552034,\n",
       "    0.00024179034517146647,\n",
       "    0.00023511683684773743,\n",
       "    0.0003435526741668582,\n",
       "    0.00020577308896463364,\n",
       "    0.0002204942429671064,\n",
       "    0.00021477705740835518,\n",
       "    0.0003019452269654721,\n",
       "    0.00022245019499678165,\n",
       "    0.00021362952247727662,\n",
       "    0.00015542644541710615,\n",
       "    0.00020899903029203415,\n",
       "    0.00014637924323324114,\n",
       "    0.00025988928973674774,\n",
       "    0.0003173321019858122,\n",
       "    0.0003522991028148681,\n",
       "    0.0001500053913332522,\n",
       "    0.00019560787768568844,\n",
       "    0.00025343330344185233,\n",
       "    0.00020520249381661415,\n",
       "    0.0002335619501536712,\n",
       "    0.00024210418632719666,\n",
       "    0.0003105060022789985,\n",
       "    0.00031310832127928734,\n",
       "    0.00024216441670432687,\n",
       "    0.0002633516560308635,\n",
       "    0.00019597694335971028,\n",
       "    0.00022390940284822136,\n",
       "    0.00032207882031798363,\n",
       "    0.000329496426275,\n",
       "    0.00021241632930468768,\n",
       "    0.0002760048082564026,\n",
       "    0.0002803057141136378,\n",
       "    0.0002561833243817091,\n",
       "    0.000199772315681912,\n",
       "    0.0002475731307640672,\n",
       "    0.0001715465186862275,\n",
       "    0.00023257112479768693,\n",
       "    0.00020794558804482222,\n",
       "    0.00026655400870367885,\n",
       "    0.0003304696874693036,\n",
       "    0.00024115850101225078,\n",
       "    0.00022958862246014178,\n",
       "    0.0002864485140889883,\n",
       "    0.00022959131456445903,\n",
       "    0.0002215990680269897,\n",
       "    0.00025282634305767715,\n",
       "    0.0002147589111700654,\n",
       "    0.0003073680563829839,\n",
       "    0.00021531923266593367,\n",
       "    0.00035955937346443534,\n",
       "    0.00029357921448536217,\n",
       "    0.0003075999266002327,\n",
       "    0.00024361083342228085,\n",
       "    0.0002229937381343916,\n",
       "    0.00019323077867738903,\n",
       "    0.00022803960018791258,\n",
       "    0.00025086250388994813,\n",
       "    0.00027536891866475344,\n",
       "    0.0001946767297340557,\n",
       "    0.0002619493752717972,\n",
       "    0.00023773475550115108,\n",
       "    0.00031313567887991667,\n",
       "    0.00023833605519030243,\n",
       "    0.00021053978707641363,\n",
       "    0.00019505909585859627,\n",
       "    0.00015764124691486359,\n",
       "    0.00021264342649374157,\n",
       "    0.0002258401073049754,\n",
       "    0.00027679544291459024,\n",
       "    0.00016303731536027044,\n",
       "    0.0002891368349082768,\n",
       "    0.0003006263286806643,\n",
       "    0.00027805069112218916,\n",
       "    0.00039677502354606986,\n",
       "    0.00019790591613855213,\n",
       "    0.00022509698465000838,\n",
       "    0.00026079892995767295,\n",
       "    0.0002488977916073054,\n",
       "    0.00015654039452783763,\n",
       "    0.0001691870711511001,\n",
       "    0.0002881876425817609,\n",
       "    0.00017998547991737723,\n",
       "    0.00034425448393449187,\n",
       "    0.00027188649983145297,\n",
       "    0.00029111304320394993,\n",
       "    0.00026038140640594065,\n",
       "    0.00023035911726765335,\n",
       "    0.0002962718717753887,\n",
       "    0.00026688812067732215,\n",
       "    0.0002253189595649019,\n",
       "    0.00015618062752764672,\n",
       "    0.0001979939261218533,\n",
       "    0.0002422239922452718,\n",
       "    0.00023813215375412256,\n",
       "    0.00023275722924154252,\n",
       "    0.00025241734692826867,\n",
       "    0.00027606773073785007,\n",
       "    0.00021815011859871447,\n",
       "    0.00027790715103037655,\n",
       "    0.00024164740170817822,\n",
       "    0.00022829201770946383,\n",
       "    0.00018908691708929837,\n",
       "    0.000286318885628134,\n",
       "    0.0002749541599769145,\n",
       "    0.00028851290699094534,\n",
       "    0.00019159942166879773,\n",
       "    0.00028517915052361786,\n",
       "    0.00024219835177063942,\n",
       "    0.00031083423527888954,\n",
       "    0.00019237285596318543,\n",
       "    0.0002724434598349035,\n",
       "    0.00025121914222836494,\n",
       "    0.0002936436503659934,\n",
       "    0.0002702067431528121,\n",
       "    0.0002355043834540993,\n",
       "    0.00022446669754572213,\n",
       "    0.0002479034010320902,\n",
       "    0.00028822870808653533,\n",
       "    0.00018270146392751485,\n",
       "    0.00021245320385787636,\n",
       "    0.0002207242214353755,\n",
       "    0.00026441767113283277,\n",
       "    0.00019587880524341017,\n",
       "    0.00027286092517897487,\n",
       "    0.00021986512001603842,\n",
       "    0.00017589112394489348,\n",
       "    0.0002556151885073632,\n",
       "    0.00026804610388353467,\n",
       "    0.00029707583598792553,\n",
       "    0.00028935514274053276,\n",
       "    0.00024072814267128706,\n",
       "    0.00030831870390102267,\n",
       "    0.0003144413058180362,\n",
       "    0.00027339530060999095,\n",
       "    0.00025350850773975253,\n",
       "    0.00020615958783309907,\n",
       "    0.00026797677855938673,\n",
       "    0.00025425938656553626,\n",
       "    0.0002167358179576695,\n",
       "    0.00022643385455012321,\n",
       "    0.0003543357306625694,\n",
       "    0.00028983294032514095,\n",
       "    0.0003593862638808787,\n",
       "    0.0003521142643876374,\n",
       "    0.00022030949185136706,\n",
       "    0.0002841894165612757,\n",
       "    0.0002607135975267738,\n",
       "    0.00019936036551371217,\n",
       "    0.00023500676616095006,\n",
       "    0.00023980952391866595,\n",
       "    0.0002061310806311667,\n",
       "    0.0002001236571231857,\n",
       "    0.00031090271659195423,\n",
       "    0.00023820949718356133,\n",
       "    0.0002208099322160706,\n",
       "    0.00022142502712085843,\n",
       "    0.00026027002604678273,\n",
       "    0.0002244877687189728,\n",
       "    0.00036224231007508934,\n",
       "    0.00036361374077387154,\n",
       "    0.00024148316879291087,\n",
       "    0.0002432127221254632,\n",
       "    0.0002869300951715559,\n",
       "    0.000199851012439467,\n",
       "    0.0002382381062489003,\n",
       "    0.00024137686705216765,\n",
       "    0.00019217362569179386,\n",
       "    0.00026189209893345833,\n",
       "    0.0002502759452909231,\n",
       "    0.0002352662559133023,\n",
       "    0.00019129287102259696,\n",
       "    0.00022707587049808353,\n",
       "    0.00016888647223822773,\n",
       "    0.0002614999539218843,\n",
       "    0.00023688293003942817,\n",
       "    0.00021801269031129777,\n",
       "    0.0002301550266565755,\n",
       "    0.00028421846218407154,\n",
       "    0.00019588494615163654,\n",
       "    0.0002421467797830701,\n",
       "    0.00031310520716942847,\n",
       "    0.0004081784572917968,\n",
       "    0.00018106734205503017,\n",
       "    0.00022153827012516558,\n",
       "    0.0002763898519333452,\n",
       "    0.00028158738859929144,\n",
       "    0.00019419589079916477,\n",
       "    0.00030439053080044687,\n",
       "    0.0002919024263974279,\n",
       "    0.000279464409686625,\n",
       "    0.00025350297801196575,\n",
       "    0.000337281875545159],\n",
       "   'fc4.weight': [0.019175559282302856,\n",
       "    0.013966994360089302,\n",
       "    0.015534082427620888,\n",
       "    0.016527967527508736,\n",
       "    0.02147395722568035,\n",
       "    0.01654520444571972,\n",
       "    0.019123323261737823,\n",
       "    0.02102295309305191,\n",
       "    0.01675349287688732,\n",
       "    0.022469546645879745,\n",
       "    0.012371083721518517,\n",
       "    0.023827169090509415,\n",
       "    0.011544322595000267,\n",
       "    0.014020093716681004,\n",
       "    0.014398603700101376,\n",
       "    0.018254291266202927,\n",
       "    0.019195744767785072,\n",
       "    0.020145639777183533,\n",
       "    0.024143559858202934,\n",
       "    0.01042915042489767,\n",
       "    0.014369822107255459,\n",
       "    0.014680982567369938,\n",
       "    0.014613387174904346,\n",
       "    0.013335994444787502,\n",
       "    0.016607021912932396,\n",
       "    0.019594209268689156,\n",
       "    0.01805969886481762,\n",
       "    0.015012585557997227,\n",
       "    0.017939001321792603,\n",
       "    0.014491160400211811,\n",
       "    0.013793922029435635,\n",
       "    0.017102809622883797,\n",
       "    0.016025042161345482,\n",
       "    0.01596982404589653,\n",
       "    0.018549542874097824,\n",
       "    0.014350040815770626,\n",
       "    0.016913171857595444,\n",
       "    0.01586821675300598,\n",
       "    0.017766078934073448,\n",
       "    0.01672157645225525,\n",
       "    0.011996288783848286,\n",
       "    0.013655942864716053,\n",
       "    0.01140540186315775,\n",
       "    0.015954788774251938,\n",
       "    0.019176527857780457,\n",
       "    0.017661258578300476,\n",
       "    0.01917833648622036,\n",
       "    0.019454963505268097,\n",
       "    0.022227684035897255,\n",
       "    0.013443075120449066,\n",
       "    0.014905941672623158,\n",
       "    0.01840684749186039,\n",
       "    0.015707816928625107,\n",
       "    0.012381309643387794,\n",
       "    0.014351556077599525,\n",
       "    0.018983658403158188,\n",
       "    0.014470767229795456,\n",
       "    0.015448992140591145,\n",
       "    0.019318019971251488,\n",
       "    0.019054554402828217,\n",
       "    0.015933437272906303,\n",
       "    0.01738039031624794,\n",
       "    0.024685241281986237,\n",
       "    0.01682564988732338,\n",
       "    0.017537718638777733,\n",
       "    0.012412922456860542,\n",
       "    0.018550029024481773,\n",
       "    0.01774926856160164,\n",
       "    0.020902901887893677,\n",
       "    0.01570521853864193,\n",
       "    0.015255077742040157,\n",
       "    0.016444548964500427,\n",
       "    0.017748935148119926,\n",
       "    0.009721487760543823,\n",
       "    0.014066900126636028,\n",
       "    0.013375279493629932,\n",
       "    0.019160110503435135,\n",
       "    0.016807038336992264,\n",
       "    0.017207453027367592,\n",
       "    0.010969385504722595,\n",
       "    0.01166683342307806,\n",
       "    0.02062288671731949,\n",
       "    0.011545096524059772,\n",
       "    0.01568988896906376,\n",
       "    0.02221205271780491,\n",
       "    0.01883849687874317,\n",
       "    0.020641641691327095,\n",
       "    0.01764458231627941,\n",
       "    0.025448055937886238,\n",
       "    0.017086226493120193,\n",
       "    0.019317736849188805,\n",
       "    0.011735950596630573,\n",
       "    0.01921241171658039,\n",
       "    0.01423155702650547,\n",
       "    0.012589999474585056,\n",
       "    0.0193342175334692,\n",
       "    0.013708403334021568,\n",
       "    0.018216369673609734,\n",
       "    0.019785059615969658,\n",
       "    0.02403789758682251,\n",
       "    0.02011716179549694,\n",
       "    0.017766587436199188,\n",
       "    0.01473501231521368,\n",
       "    0.01147471833974123,\n",
       "    0.021075382828712463,\n",
       "    0.016388650983572006,\n",
       "    0.014943378046154976,\n",
       "    0.015550900250673294,\n",
       "    0.017661653459072113,\n",
       "    0.017241328954696655,\n",
       "    0.02204976975917816,\n",
       "    0.011891808360815048,\n",
       "    0.019054194912314415,\n",
       "    0.01625053770840168,\n",
       "    0.01462912280112505,\n",
       "    0.018721964210271835,\n",
       "    0.01640552468597889,\n",
       "    0.009176264517009258,\n",
       "    0.017155032604932785,\n",
       "    0.01950765773653984,\n",
       "    0.010586495511233807,\n",
       "    0.017381716519594193,\n",
       "    0.017102863639593124,\n",
       "    0.012330292724072933,\n",
       "    0.01680801250040531,\n",
       "    0.014734196476638317,\n",
       "    0.012416011653840542,\n",
       "    0.014485331252217293,\n",
       "    0.017606856301426888,\n",
       "    0.01759101077914238,\n",
       "    0.016181886196136475,\n",
       "    0.015669813379645348,\n",
       "    0.016755729913711548,\n",
       "    0.01872425526380539,\n",
       "    0.014876111410558224,\n",
       "    0.01602334715425968,\n",
       "    0.017818886786699295,\n",
       "    0.01267610490322113,\n",
       "    0.016702333465218544,\n",
       "    0.01990603096783161,\n",
       "    0.017807992175221443,\n",
       "    0.01659725420176983,\n",
       "    0.006884456146508455,\n",
       "    0.02090180106461048,\n",
       "    0.01534620113670826,\n",
       "    0.015275468118488789,\n",
       "    0.015153598040342331,\n",
       "    0.016739463433623314,\n",
       "    0.013950958847999573,\n",
       "    0.01619740203022957,\n",
       "    0.014363814145326614,\n",
       "    0.01843988709151745,\n",
       "    0.013844971545040607,\n",
       "    0.013977393507957458,\n",
       "    0.018389131873846054,\n",
       "    0.015463435091078281,\n",
       "    0.01630263589322567,\n",
       "    0.015916060656309128,\n",
       "    0.023513834923505783,\n",
       "    0.020481834188103676,\n",
       "    0.014803583733737469,\n",
       "    0.022453729063272476,\n",
       "    0.015185615979135036,\n",
       "    0.01422713603824377,\n",
       "    0.014136836864054203,\n",
       "    0.015588168054819107,\n",
       "    0.014525660313665867,\n",
       "    0.013298163190484047,\n",
       "    0.018358809873461723,\n",
       "    0.01650295965373516,\n",
       "    0.016302211210131645,\n",
       "    0.011928679421544075,\n",
       "    0.018321599811315536,\n",
       "    0.015534604899585247,\n",
       "    0.014456932432949543,\n",
       "    0.018671296536922455,\n",
       "    0.012049848213791847,\n",
       "    0.013688454404473305,\n",
       "    0.015038956888020039,\n",
       "    0.018287496641278267,\n",
       "    0.0137040875852108,\n",
       "    0.01462964154779911,\n",
       "    0.010044969618320465,\n",
       "    0.012080937623977661,\n",
       "    0.009713124483823776,\n",
       "    0.019438395276665688,\n",
       "    0.023306896910071373,\n",
       "    0.024613721296191216,\n",
       "    0.00957831647247076,\n",
       "    0.013567587360739708,\n",
       "    0.014487297274172306,\n",
       "    0.011526938527822495,\n",
       "    0.014525596052408218,\n",
       "    0.016703471541404724,\n",
       "    0.02166890911757946,\n",
       "    0.02074277400970459,\n",
       "    0.01755398139357567,\n",
       "    0.01783604733645916,\n",
       "    0.013914735056459904,\n",
       "    0.014875824563205242,\n",
       "    0.021618399769067764,\n",
       "    0.01931697688996792,\n",
       "    0.013828884810209274,\n",
       "    0.017599845305085182,\n",
       "    0.017137881368398666,\n",
       "    0.01988866552710533,\n",
       "    0.012086051516234875,\n",
       "    0.014698637649416924,\n",
       "    0.009603614918887615,\n",
       "    0.016039934009313583,\n",
       "    0.01351072359830141,\n",
       "    0.01821613498032093,\n",
       "    0.0204105693846941,\n",
       "    0.015532947145402431,\n",
       "    0.015397477895021439,\n",
       "    0.016180872917175293,\n",
       "    0.016319014132022858,\n",
       "    0.015015186741948128,\n",
       "    0.016770336776971817,\n",
       "    0.013615071773529053,\n",
       "    0.017662134021520615,\n",
       "    0.013897188007831573,\n",
       "    0.02109244465827942,\n",
       "    0.01663157530128956,\n",
       "    0.019524715840816498,\n",
       "    0.016510317102074623,\n",
       "    0.016981782391667366,\n",
       "    0.013182399794459343,\n",
       "    0.01553442794829607,\n",
       "    0.016197804361581802,\n",
       "    0.016037989407777786,\n",
       "    0.01342855580151081,\n",
       "    0.018290268257260323,\n",
       "    0.014019092544913292,\n",
       "    0.018931735306978226,\n",
       "    0.01683983765542507,\n",
       "    0.015114910900592804,\n",
       "    0.010964768007397652,\n",
       "    0.00995896477252245,\n",
       "    0.014351866208016872,\n",
       "    0.015062746591866016,\n",
       "    0.01743227429687977,\n",
       "    0.010639254003763199,\n",
       "    0.017660493031144142,\n",
       "    0.021426696330308914,\n",
       "    0.018377214670181274,\n",
       "    0.02572791278362274,\n",
       "    0.012549128383398056,\n",
       "    0.014104852452874184,\n",
       "    0.019333491101861,\n",
       "    0.016040220856666565,\n",
       "    0.010500236414372921,\n",
       "    0.009766023606061935,\n",
       "    0.021975195035338402,\n",
       "    0.012046599760651588,\n",
       "    0.02281755581498146,\n",
       "    0.018390454351902008,\n",
       "    0.015937943011522293,\n",
       "    0.015135971829295158,\n",
       "    0.01668374240398407,\n",
       "    0.017469171434640884,\n",
       "    0.017606593668460846,\n",
       "    0.01285204105079174,\n",
       "    0.010289542376995087,\n",
       "    0.013686980120837688,\n",
       "    0.017661090940237045,\n",
       "    0.015222197398543358,\n",
       "    0.015275775454938412,\n",
       "    0.018723009154200554,\n",
       "    0.017313983291387558,\n",
       "    0.015675392001867294,\n",
       "    0.01826980710029602,\n",
       "    0.016302717849612236,\n",
       "    0.012849143706262112,\n",
       "    0.013775746338069439,\n",
       "    0.0155839454382658,\n",
       "    0.019196035340428352,\n",
       "    0.019108684733510017,\n",
       "    0.009780948050320148,\n",
       "    0.017590798437595367,\n",
       "    0.01539628580212593,\n",
       "    0.021443292498588562,\n",
       "    0.013409320265054703,\n",
       "    0.015345344319939613,\n",
       "    0.01581292226910591,\n",
       "    0.017608728259801865,\n",
       "    0.017345193773508072,\n",
       "    0.016371360048651695,\n",
       "    0.01606079190969467,\n",
       "    0.018375100567936897,\n",
       "    0.01922989822924137,\n",
       "    0.011279374361038208,\n",
       "    0.012987976893782616,\n",
       "    0.0152728958055377,\n",
       "    0.019106227904558182,\n",
       "    0.011676399037241936,\n",
       "    0.017311282455921173,\n",
       "    0.014470210298895836,\n",
       "    0.010149303823709488,\n",
       "    0.017605923116207123,\n",
       "    0.01814570650458336,\n",
       "    0.018127020448446274,\n",
       "    0.021687118336558342,\n",
       "    0.018392764031887054,\n",
       "    0.01872323825955391,\n",
       "    0.021006133407354355,\n",
       "    0.019961869344115257,\n",
       "    0.015256265178322792,\n",
       "    0.01342974416911602,\n",
       "    0.013964527286589146,\n",
       "    0.01647629588842392,\n",
       "    0.01541314646601677,\n",
       "    0.015414312481880188,\n",
       "    0.020753225311636925,\n",
       "    0.019191300496459007,\n",
       "    0.024107467383146286,\n",
       "    0.025327889248728752,\n",
       "    0.013563985005021095,\n",
       "    0.017886638641357422,\n",
       "    0.019455162808299065,\n",
       "    0.012688442133367062,\n",
       "    0.014699150808155537,\n",
       "    0.015659229829907417,\n",
       "    0.013966609723865986,\n",
       "    0.013268111273646355,\n",
       "    0.01647588051855564,\n",
       "    0.015188069082796574,\n",
       "    0.013774930499494076,\n",
       "    0.013735443353652954,\n",
       "    0.01525091752409935,\n",
       "    0.014612297527492046,\n",
       "    0.020658930763602257,\n",
       "    0.020169928669929504,\n",
       "    0.01395095232874155,\n",
       "    0.016181277111172676,\n",
       "    0.01905335672199726,\n",
       "    0.012798052281141281,\n",
       "    0.01515553891658783,\n",
       "    0.016824722290039062,\n",
       "    0.013166665099561214,\n",
       "    0.01618080399930477,\n",
       "    0.016192954033613205,\n",
       "    0.015586678870022297,\n",
       "    0.013949931599199772,\n",
       "    0.015013713389635086,\n",
       "    0.011998516507446766,\n",
       "    0.018576323986053467,\n",
       "    0.016302967444062233,\n",
       "    0.013759332709014416,\n",
       "    0.014456728473305702,\n",
       "    0.01865367963910103,\n",
       "    0.01215558871626854,\n",
       "    0.016250129789114,\n",
       "    0.01858326978981495,\n",
       "    0.02149493619799614,\n",
       "    0.01128419954329729,\n",
       "    0.014730752445757389,\n",
       "    0.01821725443005562,\n",
       "    0.01875779591500759,\n",
       "    0.012300776317715645,\n",
       "    0.01491861417889595,\n",
       "    0.016565224155783653,\n",
       "    0.01476566307246685,\n",
       "    0.016371147707104683,\n",
       "    0.024649539962410927]})]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-spray",
   "metadata": {},
   "source": [
    "<p>After collecting all parameter gradients of all logistic regression model variants, a corresponding comparing visualization is well suited to illustrate the <i>Vanishing Gradient Problem</i>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "further-shopper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare collected gradients for plotting.\n",
    "gradient_dfs = []\n",
    "for model, gradient in gradients:\n",
    "    gradient_data = pd.DataFrame(gradient)\n",
    "    gradient_data.columns = [f\"Layer {i + 1}\" for i in range(len(gradient))]\n",
    "    gradient_data = pd.melt(gradient_data, var_name=\"Layer\", value_name=\"Gradient Magnitude\")\n",
    "    gradient_data[\"Model\"] = type(model).__name__\n",
    "    gradient_dfs.append(gradient_data)\n",
    "\n",
    "# Combine all gradients in a single data frame.\n",
    "gradients_df = pd.concat(gradient_dfs)\n",
    "\n",
    "# Define plotting figure and corresponding attributes.\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.set(yscale='log')\n",
    "\n",
    "# Plot pre-processed gradients.\n",
    "sns.boxplot(x='Model', y='Gradient Magnitude', hue='Layer', data=gradients_df, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-apparel",
   "metadata": {},
   "source": [
    "<a name=\"vanishing-gradient\"></a><h2>The Vanishing Gradient Problem (Revised)</h2>\n",
    "<p>The <i>Vanishing Gradient Problem</i> describes the effect of <i>losing</i> the error signal on its way from the loss function to the network's input. As a result, the gradients in the lower layers of a network receive almost no error signal to adapt the parameters accordingly. It is especially pronounced in deep neural networks, so more layers can be counterproductive.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-termination",
   "metadata": {},
   "source": [
    "<a name=\"vanishing-gradient-culprit\"></a><h3 style=\"color:rgb(0,120,170)\">The primary culprit</h3>\n",
    "<p>Remember the <i>backward</i> pass as discussed earlier in this unit. Gradients multiply according to the <i>chain rule</i>. Hence, with respect to our logistic regression models, this includes many derivatives of the sigmoid activation function.\n",
    "\n",
    "<center>\n",
    "    \\begin{align*}\n",
    "    \\mathbf{W}_4 & \\leftarrow \\mathbf{W}_4 - \\eta \\frac{\\partial L}{\\partial \\mathbf{W}_4} \\\\\n",
    "    \\mathbf{W}_3 & \\leftarrow \\mathbf{W}_3 - \\eta \\frac{\\partial L}{\\partial h^{(3)}}\\frac{\\partial h^{(3)}}{\\partial \\mathbf{W}_3} \\\\\n",
    "    \\mathbf{W}_2 & \\leftarrow \\mathbf{W}_2 - \\eta \\frac{\\partial L}{\\partial h^{(3)}}\\frac{\\partial h^{(3)}}{\\partial h^{(2)}}\\frac{\\partial h^{(2)}}{\\partial \\mathbf{W}_2} \\\\\n",
    "    \\mathbf{W}_1 & \\leftarrow \\mathbf{W}_1 - \\eta \\underbrace{\\frac{\\partial L}{\\partial h^{(3)}}}_{\\sim\\sigma'}\\underbrace{\\frac{\\partial h^{(3)}}{\\partial h^{(2)}}}_{\\sim\\sigma'}\\underbrace{\\frac{\\partial h^{(2)}}{\\partial h^{(1)}}}_{\\sim\\sigma'}\\underbrace{\\frac{\\partial h^{(1)}}{\\partial \\mathbf{W}_1}}_{\\sim\\sigma'}\n",
    "    \\end{align*}\n",
    "</center>\n",
    "\n",
    "For this very reason, let's have a closer look at the <i>sigmoid</i> activation function and its derivative.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "caroline-presence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(-10.0): 0.0000 | sigmoid'(-10.0): 0.0000\n",
      "sigmoid(  0.0): 0.5000 | sigmoid'(  0.0): 0.2500\n",
      "sigmoid( 10.0): 1.0000 | sigmoid'( 10.0): 0.0000\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the logistic function.\n",
    "    \n",
    "    :param x: the input on which to apply the logistic function\n",
    "    :return: the result of the logistic function applied to its input\n",
    "    \"\"\"\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_d(x: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the derivate of the logistic function.\n",
    "    \n",
    "    :param x: the input to the logistic function for computing its derivative\n",
    "    :return: the derivative of the logistic function with respect to its input\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))\n",
    "\n",
    "\n",
    "# Crudly check the value range of the sigmoid function and its derivative.\n",
    "for x in [-10.0, 0.0, 10.0]:\n",
    "    print(f'sigmoid({x:>5}): {sigmoid(x):.4f} | sigmoid\\'({x:>5}): {sigmoid_d(x):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-klein",
   "metadata": {},
   "source": [
    "<p>The previous computation of the value range of the sigmoid function and its derivative already suggests that the derivative vanishes if the corresponding input is either <i>small</i> or <i>big</i> – which already seems problematic. For a more thorough analysis, let's visualize the value ranges accordingly.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "south-tonight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_sigmoid_with_derivative(x_min: float = -5.0, x_max: float = 5.0, granularity: int = 1000) -> None:\n",
    "    \"\"\"\n",
    "    Plot the logistic function including its derivative.\n",
    "    \n",
    "    :param x_min: minimum value of the input value range\n",
    "    :param x_max: maximum value of the input value range\n",
    "    :param granularity: granularity controlling the stepsize of the input value range\n",
    "    \"\"\"\n",
    "    data = np.linspace(x_min, x_max, granularity)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    ax.spines['left'].set_position('center')\n",
    "\n",
    "    plt.plot(data, tuple(map(sigmoid, data)), color='#307EC7', linewidth=3, label='sigmoid')\n",
    "    plt.plot(data, tuple(map(sigmoid_d, data)), color='#accbe8', linewidth=3, label=\"sigmoid'\")\n",
    "    plt.title('Sigmoid function', fontsize=20)\n",
    "    plt.legend(prop={'size': 15})\n",
    "    plt.show()\n",
    "\n",
    "# Plot logistic function including its derivative.\n",
    "plot_sigmoid_with_derivative()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-webcam",
   "metadata": {},
   "source": [
    "<a name=\"vanishing-gradient-relu\"></a><h3 style=\"color:rgb(0,120,170)\">Rectified linear units to the rescue</h3>\n",
    "<p>It seems quite clear, that we need to exchange the <i>sigmoid</i> activation function with a different one. Ideally, the new activation function should have a derivative close to $1$ in order to mitigate a <i>vanishing gradient</i> (likewise an <i>exploding gradient</i>). A common activation function is the <i>rectified linear unit</i> (often abbreviated as <i>ReLU</i>), which is easy and efficient to compute and provides a derivative of <i>exactly</i> $1$ for all positive inputs.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "vanilla-mixture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu(-10.0):  0.0000 | relu'(-10.0): 0.0000\n",
      "relu(  0.0):  0.0000 | relu'(  0.0): 0.0000\n",
      "relu( 10.0): 10.0000 | relu'( 10.0): 1.0000\n"
     ]
    }
   ],
   "source": [
    "def relu(x: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the rectified linear unit function.\n",
    "    \n",
    "    :param x: the input on which to apply the rectified linear unit function\n",
    "    :return: the result of the rectified linear unit function applied to its input\n",
    "    \"\"\"\n",
    "    return max(0.0, x)\n",
    "\n",
    "\n",
    "def relu_d(x: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the derivate of the rectified linear unit function.\n",
    "    \n",
    "    :param x: the input to the rectified linear unit function for computing its derivative\n",
    "    :return: the derivative of the rectified linear unit function with respect to its input\n",
    "    \"\"\"\n",
    "    return 0.0 if x <= 0.0 else 1.0\n",
    "\n",
    "\n",
    "# Crudly check the value range of the rectified linear unit function and its derivative.\n",
    "for x in [-10.0, 0.0, 10.0]:\n",
    "    print(f'relu({x:>5}): {relu(x):7.4f} | relu\\'({x:>5}): {relu_d(x):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "early-baghdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_relu_with_derivative(x_min: float = -2.5, x_max: float = 2.5, granularity: int = 1000) -> None:\n",
    "    \"\"\"\n",
    "    Plot the rectified linear unit function including its derivative.\n",
    "    \n",
    "    :param x_min: minimum value of the input value range\n",
    "    :param x_max: maximum value of the input value range\n",
    "    :param granularity: granularity controlling the stepsize of the input value range\n",
    "    \"\"\"\n",
    "    data = np.linspace(x_min, x_max, granularity)\n",
    "    data_pivot_neg = np.where(data <= 0)\n",
    "    data_pivot_pos = np.where(data > 0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    ax.spines['left'].set_position('center')\n",
    "\n",
    "    plt.plot(data, tuple(map(relu, data)), color='#e22182', linewidth=3, label='relu')\n",
    "    # Plot derivative of negative/positive data separately to avoid a linked line plot.\n",
    "    if len(data_pivot_neg) > 0:\n",
    "        data_neg = data[data_pivot_neg]\n",
    "        plt.plot(data_neg, tuple(map(relu_d, data_neg)), color='#accbe8', linewidth=3, label=\"relu'\")\n",
    "    if len(data_pivot_pos) > 0:\n",
    "        data_pos = data[data_pivot_pos]\n",
    "        plt.plot(data_pos, tuple(map(relu_d, data_pos)), color='#accbe8', linewidth=3)\n",
    "    plt.title('ReLU function', fontsize=20)\n",
    "    plt.legend(prop={'size': 15})\n",
    "    plt.show()\n",
    "\n",
    "# Plot rectified linear unit function including its derivative.\n",
    "plot_relu_with_derivative()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-bleeding",
   "metadata": {},
   "source": [
    "<a name=\"training-relu\"></a><h3 style=\"color:rgb(0,120,170)\">Training of a ReLU-Network</h3>\n",
    "<p>After analyzing the value range of the <i>rectified linear unit</i> function including its derivative, we are now creating a corresponding network to check how the performance changes with respect to the previous <code>LogisticRegression3H</code> implementation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "accomplished-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU3H(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    ReLU network tailored to process Fashion-MNIST data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, 28 * 28)\n",
    "        self.ac1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(self.fc1.out_features, self.fc1.out_features)\n",
    "        self.ac2 = torch.nn.ReLU()\n",
    "        self.fc3 = torch.nn.Linear(self.fc2.out_features, self.fc2.out_features)\n",
    "        self.ac3 = torch.nn.ReLU()\n",
    "        self.fc4 = torch.nn.Linear(self.fc3.out_features, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ac2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.ac3(x)\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fitted-allen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU3H(\n",
      "  (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (ac1): ReLU()\n",
      "  (fc2): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (ac2): ReLU()\n",
      "  (fc3): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (ac3): ReLU()\n",
      "  (fc4): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility.\n",
    "u2.set_seed(0)\n",
    "\n",
    "# Create ReLU network instance and the corresponding optimizer to use.\n",
    "relu_model = ReLU3H()\n",
    "optimizer = torch.optim.SGD(relu_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Show the architecture of the ReLU network model.\n",
    "print(relu_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "small-estate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / Train loss: 0.0179 / Train accuracy: 0.1850\n",
      "Epoch: 2 / Train loss: 0.0178 / Train accuracy: 0.2203\n",
      "Epoch: 3 / Train loss: 0.0177 / Train accuracy: 0.2432\n",
      "\n",
      "Test loss: 0.0177 / Test accuracy: 0.2410\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility.\n",
    "u2.set_seed(0)\n",
    "\n",
    "# Train and evaluate ReLU network instance on the Fashion-MNIST training set.\n",
    "train_and_evaluate(\n",
    "    model=relu_model,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=3,\n",
    "    loader_train=loader_fashion_mnist_train,\n",
    "    loader_test=loader_fashion_mnist_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-flight",
   "metadata": {},
   "source": [
    "<p>Compared to the 3-layer logisitc regression model from above, the results seem to have improved significantly. We are performing a corresponding <i>gradient analysis</i> to investigate if the <i>vanishing gradient</i> is now absent. Assumptions are all nice and good, but a in a proper workflow, checking of assumptions is a <i>must</i> (if possible). For this very reason, we are creating <i>new</i> instances of <code>ReLU3H</code> as well as <code>LogisticRegression3H</code> for a comparison.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "experimental-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for model_class in [LogisticRegression3H, ReLU3H]:\n",
    "    # Set random seed for reproducibility.\n",
    "    u2.set_seed(0)\n",
    "    \n",
    "    # Create logistic regression models.\n",
    "    models.append(model_class())\n",
    "\n",
    "gradients = [(model, collect_gradients(model=model, loader=loader_fashion_mnist_train)) for model in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-sacrifice",
   "metadata": {},
   "source": [
    "<p>After collecting all parameter gradients of the rectified linear unit as well as the corresponding logistic regression model, an adequate comparing visualization is well suited to illustrate the <i>Vanishing Gradient Problem</i> (or its <i>absence</i>).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "finite-recruitment",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare collected gradients for plotting.\n",
    "gradient_dfs = []\n",
    "for model, gradient in gradients:\n",
    "    gradient_data = pd.DataFrame(gradient)\n",
    "    gradient_data.columns = [f\"Layer {i + 1}\" for i in range(len(gradient))]\n",
    "    gradient_data = pd.melt(gradient_data, var_name=\"Layer\", value_name=\"Gradient Magnitude\")\n",
    "    gradient_data[\"Model\"] = type(model).__name__\n",
    "    gradient_dfs.append(gradient_data)\n",
    "\n",
    "# Combine all gradients in a single data frame.\n",
    "gradients_df = pd.concat(gradient_dfs)\n",
    "\n",
    "# Define plotting figure and corresponding attributes.\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.set(yscale='log')\n",
    "\n",
    "# Plot pre-processed gradients.\n",
    "sns.boxplot(x='Model', y='Gradient Magnitude', hue='Layer', data=gradients_df, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6c042c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
